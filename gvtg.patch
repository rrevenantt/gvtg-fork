From ef0bad4b5e7f370b32a3826add1ab03a7bb5b46e Mon Sep 17 00:00:00 2001
From: Konstantin Anisimov <rrevenantt@gmail.com>
Date: Mon, 4 May 2015 04:09:14 +0300
Subject: [PATCH 1/3] most changes done

---
 drivers/gpu/drm/i915/vgt/aperture_gm.c |   5 +-
 drivers/gpu/drm/i915/vgt/cmd_parser.c  |  20 +++-
 drivers/gpu/drm/i915/vgt/display.c     |  29 ++++-
 drivers/gpu/drm/i915/vgt/handlers.c    |  46 +++++---
 drivers/gpu/drm/i915/vgt/instance.c    |   3 +-
 drivers/gpu/drm/i915/vgt/interrupt.c   |  50 ++++++++-
 drivers/gpu/drm/i915/vgt/sysfs.c       | 197 +++++++++++++++++++++++++++++++++
 drivers/gpu/drm/i915/vgt/vgt.c         |   7 ++
 drivers/gpu/drm/i915/vgt/vgt.h         |  11 +-
 9 files changed, 335 insertions(+), 33 deletions(-)

diff --git a/drivers/gpu/drm/i915/vgt/aperture_gm.c b/drivers/gpu/drm/i915/vgt/aperture_gm.c
index 25dea5b..2d585fa 100644
--- a/drivers/gpu/drm/i915/vgt/aperture_gm.c
+++ b/drivers/gpu/drm/i915/vgt/aperture_gm.c
@@ -67,7 +67,10 @@ vgt_reg_t mmio_g2h_gmadr(struct vgt_device *vgt, unsigned long reg, vgt_reg_t g_
 	 *  Note: ASSERT_VM should be placed outside, e.g. after lock is released in
 	 *  vgt_emulate_write(). Will fix this later.
 	 */
-	ASSERT_VM(!ret, vgt);
+//	if(vgt->vm_id == 0)
+//		{ASSERT(!ret);}
+//	else
+//		ASSERT_VM(!ret, vgt);
 	vgt_dbg(VGT_DBG_MEM, "....(g)%x->(h)%llx\n", g_value, (h_value & mask) | (g_value & ~mask));
 
 	return (h_value & mask) | (g_value & ~mask);
diff --git a/drivers/gpu/drm/i915/vgt/cmd_parser.c b/drivers/gpu/drm/i915/vgt/cmd_parser.c
index c8542f5..2c857b1 100644
--- a/drivers/gpu/drm/i915/vgt/cmd_parser.c
+++ b/drivers/gpu/drm/i915/vgt/cmd_parser.c
@@ -1065,7 +1065,8 @@ static int vgt_handle_mi_display_flip(struct parser_exec_state *s, bool resubmit
 	msg.plane_id = plane;
 	vgt_fb_notifier_call_chain(FB_DISPLAY_FLIP, &msg);
 
-	if ((s->vgt == current_foreground_vm(s->vgt->pdev)) && !resubmitted) {
+	if (s->vgt->pdev->vgt_on_pipe[real_pipe] == s->vgt && !resubmitted){
+//	if ((s->vgt == current_foreground_vm(s->vgt->pdev)) && !resubmitted) {
 		if(!display_flip_encode_plane_info(real_pipe, plane, &real_plane_code))
 			goto wrong_command;
 
@@ -1127,11 +1128,11 @@ static int vgt_handle_mi_wait_for_event(struct parser_exec_state *s)
 	if (!is_wait_for_flip_pending(cmd))
 		return rc;
 
-	if (s->vgt != current_foreground_vm(s->vgt->pdev)) {
-		rc |= add_patch_entry(s, cmd_ptr(s, 0), MI_NOOP);
-		vgt_dbg(VGT_DBG_CMD, "VM %d: mi_wait_for_event to be ignored\n", s->vgt->vm_id);
-		return rc;
-	}
+//	if (s->vgt != current_foreground_vm(s->vgt->pdev)) {
+//		rc |= add_patch_entry(s, cmd_ptr(s, 0), MI_NOOP);
+//		vgt_dbg(VGT_DBG_CMD, "VM %d: mi_wait_for_event to be ignored\n", s->vgt->vm_id);
+//		return rc;
+//	}
 
 	if (cmd & MI_WAIT_FOR_PLANE_A_FLIP_PENDING) {
 		virtual_pipe = PIPE_A;
@@ -1163,6 +1164,13 @@ static int vgt_handle_mi_wait_for_event(struct parser_exec_state *s)
 
 	real_pipe = s->vgt->pipe_mapping[virtual_pipe];
 
+	if (s->vgt != s->vgt->pdev->vgt_on_pipe[real_pipe]){
+		rc |= add_patch_entry(s, cmd_ptr(s, 0), MI_NOOP);
+		vgt_dbg(VGT_DBG_CMD, "VM %d: mi_wait_for_event to be ignored\n", s->vgt->vm_id);
+		return rc;
+	}
+
+
 	if (real_pipe == PIPE_A && plane_type == PRIMARY_PLANE) {
 		new_cmd |= MI_WAIT_FOR_PLANE_A_FLIP_PENDING;
 	} else if (real_pipe == PIPE_B && plane_type == PRIMARY_PLANE) {
diff --git a/drivers/gpu/drm/i915/vgt/display.c b/drivers/gpu/drm/i915/vgt/display.c
index 0599c72..06712f9 100644
--- a/drivers/gpu/drm/i915/vgt/display.c
+++ b/drivers/gpu/drm/i915/vgt/display.c
@@ -126,15 +126,28 @@ void do_vgt_fast_display_switch(struct pgt_device *pdev)
 
 	ASSERT(fastpath_dpy_switch);
 	ASSERT(spin_is_locked(&pdev->lock));
-
+	if (to_vgt != current_foreground_vm(pdev)){
+		for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) 
+			if (_PRI_PLANE_ENABLE & __vreg(to_vgt, VGT_DSPCNTR(pipe))) {
+				pdev->vgt_on_pipe[to_vgt->pipe_mapping[pipe]] = to_vgt;
+				vgt_restore_state(to_vgt, pipe);
+				set_panel_fitting(to_vgt, pipe);
+				
+			}
+		current_foreground_vm(pdev) = to_vgt;
+		
+	} else
 	for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) {
-		vgt_restore_state(to_vgt, pipe);
-		if (_PRI_PLANE_ENABLE & __vreg(to_vgt, VGT_DSPCNTR(pipe))) {
-			set_panel_fitting(to_vgt, pipe);
+		if (pdev->next_vgt_on_pipe[pipe] != NULL 
+			&& _PRI_PLANE_ENABLE & __vreg(pdev->next_vgt_on_pipe[pipe], VGT_DSPCNTR(pipe))){
+			pdev->vgt_on_pipe[pipe] = pdev->next_vgt_on_pipe[pipe];
+			vgt_restore_state(pdev->next_vgt_on_pipe[pipe], pipe);
+			set_panel_fitting(pdev->next_vgt_on_pipe[pipe], pipe);
+			pdev->next_vgt_on_pipe[pipe] = NULL;				
 		}
 	}
 
-	current_foreground_vm(pdev) = to_vgt;
+	
 }
 
 static inline int get_event_and_edid_info(vgt_hotplug_cmd_t cmd,
@@ -517,6 +530,7 @@ bool rebuild_pipe_mapping(struct vgt_device *vgt, unsigned int reg, uint32_t new
 
 	if (current_foreground_vm(vgt->pdev) == vgt) {
 		vgt_restore_state(vgt, virtual_pipe);
+		vgt->pdev->vgt_on_pipe[physical_pipe] = vgt;
 	}
 
 	return true;
@@ -579,6 +593,8 @@ bool update_pipe_mapping(struct vgt_device *vgt, unsigned int physical_reg, uint
 
 	if (virtual_pipe != I915_MAX_PIPES) {
 		vgt_set_pipe_mapping(vgt, virtual_pipe, physical_pipe);
+		if (current_foreground_vm(vgt->pdev) == vgt)
+			vgt->pdev->vgt_on_pipe[physical_pipe] = vgt;
 		vgt_dbg(VGT_DBG_DPY, "vGT: Update pipe mapping  %x - > %x \n", virtual_pipe, physical_pipe);
 		vgt_update_irq_reg(vgt);
 		if (vgt_has_pipe_enabled(vgt, virtual_pipe))
@@ -586,7 +602,8 @@ bool update_pipe_mapping(struct vgt_device *vgt, unsigned int physical_reg, uint
 		vgt_calculate_frmcount_delta(vgt, virtual_pipe);
 	}
 
-	if (current_foreground_vm(vgt->pdev) == vgt &&
+//	if (current_foreground_vm(vgt->pdev) == vgt &&
+	if (vgt->pdev->vgt_on_pipe[physical_pipe] == vgt &&
 		virtual_pipe != I915_MAX_PIPES &&
 		(_PRI_PLANE_ENABLE & VGT_MMIO_READ(vgt->pdev, VGT_DSPCNTR(physical_pipe)))) {
 		vgt_restore_state(vgt, virtual_pipe);
diff --git a/drivers/gpu/drm/i915/vgt/handlers.c b/drivers/gpu/drm/i915/vgt/handlers.c
index cd95e75..80b7182 100644
--- a/drivers/gpu/drm/i915/vgt/handlers.c
+++ b/drivers/gpu/drm/i915/vgt/handlers.c
@@ -718,6 +718,7 @@ static bool dpy_trans_ddi_ctl_write(struct vgt_device *vgt, unsigned int offset,
 
 	/* if it is to enable this pipe, then rebuild the mapping for this pipe*/
 	if (is_current_display_owner(vgt)) {
+//	if (vgt->pdev->vgt_on_pipe[get_pipe(offset, new_data)] == vgt)
 		/*when dom0 change the physical pipe/port connection,
 		we need to rebuild pipe mapping for the vgt device.*/
 		for (i = 0; i < VGT_MAX_VMS; ++ i) {
@@ -1261,10 +1262,14 @@ static bool dpy_plane_mmio_write(struct vgt_device *vgt, unsigned int offset,
 
 	memcpy ((char *)vgt->state.vReg + offset, p_data, bytes);
 	memcpy ((char *)vgt->state.sReg + offset, p_data, bytes);
-	if (current_foreground_vm(vgt->pdev) == vgt &&
-		vgt_map_plane_reg(vgt, offset, &real_offset)) {
-		VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
-	}
+	if (vgt_map_plane_reg(vgt, offset, &real_offset) &&
+		vgt->pdev->vgt_on_pipe[(real_offset & 0x3000) >> 12] == vgt){
+			VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+	}
+//	if (current_foreground_vm(vgt->pdev) == vgt &&
+//		vgt_map_plane_reg(vgt, offset, &real_offset)) {
+//		VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+//	}
 	return true;
 }
 
@@ -1288,6 +1293,7 @@ static bool dpy_plane_ctl_write(struct vgt_device *vgt, unsigned int offset,
 	dpy_plane_mmio_write(vgt, offset, p_data, bytes);
 	if (enable_plane) {
 		if (current_foreground_vm(vgt->pdev) == vgt) {
+//		if (vgt->pdev->vgt_on_pipe == vgt){
 			set_panel_fitting(vgt, pipe);
 		} else if (is_current_display_owner(vgt)) {
 			p_pipe = vgt->pipe_mapping[pipe];
@@ -1323,10 +1329,14 @@ static bool pri_surf_mmio_write(struct vgt_device *vgt, unsigned int offset,
 
 	__vreg(vgt, VGT_PIPE_FLIPCOUNT(pipe))++;
 
-	if (current_foreground_vm(vgt->pdev) == vgt &&
-		vgt_map_plane_reg(vgt, offset, &real_offset)) {
-		VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+	if (vgt_map_plane_reg(vgt, offset, &real_offset) &&
+		vgt->pdev->vgt_on_pipe[VGT_DSPSURFPIPE(real_offset)] == vgt){
+			VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
 	}
+//	if (current_foreground_vm(vgt->pdev) == vgt &&
+//		vgt_map_plane_reg(vgt, offset, &real_offset)) {
+//		VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+//	}
 
 	msg.vm_id = vgt->vm_id;
 	msg.plane_id = PRIMARY_PLANE;
@@ -1361,11 +1371,16 @@ static bool spr_surf_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	ret_val = vgt_surf_base_range_check(vgt, pipe, SPRITE_PLANE);
 	__sreg(vgt, offset) = ret_val ? ret_val : __vreg(vgt, offset);
 
-	if (current_foreground_vm(vgt->pdev) == vgt &&
-		vgt_map_plane_reg(vgt, offset, &real_offset)) {
-		VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+	if (vgt_map_plane_reg(vgt, offset, &real_offset) &&
+		vgt->pdev->vgt_on_pipe[VGT_SPRSURFPIPE(real_offset)] == vgt){
+			VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
 	}
 
+//	if (current_foreground_vm(vgt->pdev) == vgt &&
+//		vgt_map_plane_reg(vgt, offset, &real_offset)) {
+//		VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+//	}
+
 	msg.vm_id = vgt->vm_id;
 	msg.plane_id = SPRITE_PLANE;
 	msg.pipe_id = VGT_SPRSURFPIPE(offset);
@@ -1396,11 +1411,16 @@ static bool cur_surf_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	ret_val = vgt_surf_base_range_check(vgt, pipe, CURSOR_PLANE);
 	__sreg(vgt, offset) = ret_val ? ret_val : __vreg(vgt, offset);
 
-	if (current_foreground_vm(vgt->pdev) == vgt &&
-		vgt_map_plane_reg(vgt, offset, &real_offset)) {
-		VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+	if (vgt_map_plane_reg(vgt, offset, &real_offset) &&
+		vgt->pdev->vgt_on_pipe[VGT_CURSURFPIPE(real_offset)] == vgt){
+			VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
 	}
 
+//	if (current_foreground_vm(vgt->pdev) == vgt &&
+//		vgt_map_plane_reg(vgt, offset, &real_offset)) {
+//		VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+//	}
+
 	return true;
 }
 
diff --git a/drivers/gpu/drm/i915/vgt/instance.c b/drivers/gpu/drm/i915/vgt/instance.c
index cb2a3e2..aa1b273 100644
--- a/drivers/gpu/drm/i915/vgt/instance.c
+++ b/drivers/gpu/drm/i915/vgt/instance.c
@@ -95,7 +95,8 @@ static int create_state_instance(struct vgt_device *vgt)
 	}
 
 	for (i = 0; i < I915_MAX_PIPES; i++) {
-		vgt->pipe_mapping[i] = i;
+		//vgt->pipe_mapping[i] = i;
+		vgt->pipe_mapping[i] = vgt->vm_id==0 ? i : I915_MAX_PIPES;
 	}
 
 	for (i = 0; i < VGT_BAR_NUM; i++)
diff --git a/drivers/gpu/drm/i915/vgt/interrupt.c b/drivers/gpu/drm/i915/vgt/interrupt.c
index ba1625c..309032f 100644
--- a/drivers/gpu/drm/i915/vgt/interrupt.c
+++ b/drivers/gpu/drm/i915/vgt/interrupt.c
@@ -1188,6 +1188,34 @@ static enum vgt_event_type translate_physical_event(struct vgt_device *vgt,
 
 /* =======================pEvent Handlers===================== */
 
+static void vgt_handle_pipe_vsync(struct vgt_irq_host_state *hstate,
+	enum vgt_event_type event){
+	int i;
+	enum vgt_event_type newevent;
+	for (i = 0; i< VGT_MAX_VMS; i++){
+		if (hstate->pdev->device[i]){
+			newevent = translate_physical_event(hstate->pdev->device[i], event);
+			vgt_handle_default_event_virt(hstate, newevent ,hstate->pdev->device[i]);
+		}
+	}
+}
+
+static void vgt_handle_pipe_vblank(struct vgt_irq_host_state *hstate,
+	enum vgt_event_type event){
+	int i;
+	enum vgt_event_type newevent;
+	for (i = 0; i< VGT_MAX_VMS; i++){
+		if (hstate->pdev->device[i]){
+			newevent = translate_physical_event(hstate->pdev->device[i], event);
+			vgt_handle_default_event_virt(hstate, newevent ,hstate->pdev->device[i]);
+		}
+	}
+//	for( i = 0; i < I915_MAX_PIPES; i++){
+//		newevent = translate_physical_event(hstate->pdev->vgt_on_pipe[i], event);
+//		vgt_handle_default_event_virt(hstate, newevent ,hstate->pdev->vgt_on_pipe[i]);
+//	}
+}
+
 static void vgt_handle_default_event_phys(struct vgt_irq_host_state *hstate,
 	enum vgt_event_type event)
 {
@@ -1859,13 +1887,18 @@ void vgt_emulate_dpy_events(struct pgt_device *pdev)
 	ASSERT(spin_is_locked(&pdev->lock));
 	for (i = 0; i < VGT_MAX_VMS; i ++) {
 		struct vgt_device *vgt = pdev->device[i];
+		int j;
 
-		if (!vgt || is_current_display_owner(vgt))
+//		if (!vgt || is_current_display_owner(vgt))
+		if (!vgt )
 			continue;
 
-		vgt_emulate_vblank(vgt, PIPE_A);
-		vgt_emulate_vblank(vgt, PIPE_B);
-		vgt_emulate_vblank(vgt, PIPE_C);
+		for (j = 0; j < I915_MAX_PIPES; j++){
+			if (vgt->pdev->vgt_on_pipe[j] == vgt)
+				continue;
+
+//temp			vgt_emulate_vblank(vgt, j);
+		}
 	}
 }
 
@@ -1980,6 +2013,12 @@ static void vgt_init_events(
 	SET_P_HANDLER(hstate, DP_B_HOTPLUG, vgt_handle_port_hotplug_phys);
 	SET_P_HANDLER(hstate, DP_C_HOTPLUG, vgt_handle_port_hotplug_phys);
 	SET_P_HANDLER(hstate, DP_D_HOTPLUG, vgt_handle_port_hotplug_phys);
+	SET_P_HANDLER(hstate, PIPE_A_VSYNC, vgt_handle_pipe_vsync);
+	SET_P_HANDLER(hstate, PIPE_B_VSYNC, vgt_handle_pipe_vsync);
+	SET_P_HANDLER(hstate, PIPE_C_VSYNC, vgt_handle_pipe_vsync);
+	SET_P_HANDLER(hstate, PIPE_A_VBLANK, vgt_handle_pipe_vblank);
+	SET_P_HANDLER(hstate, PIPE_B_VBLANK, vgt_handle_pipe_vblank);
+	SET_P_HANDLER(hstate, PIPE_C_VBLANK, vgt_handle_pipe_vblank);
 
 	SET_P_HANDLER(hstate, RCS_AS_CONTEXT_SWITCH, vgt_handle_ctx_switch_phys);
 	SET_P_HANDLER(hstate, VCS_AS_CONTEXT_SWITCH, vgt_handle_ctx_switch_phys);
@@ -2217,7 +2256,8 @@ void vgt_fini_irq(struct pci_dev *pdev)
 void vgt_inject_flip_done(struct vgt_device *vgt, enum vgt_pipe pipe)
 {
 	enum vgt_event_type event = EVENT_MAX;
-	if (current_foreground_vm(vgt->pdev) != vgt) {
+//	if (current_foreground_vm(vgt->pdev) != vgt) {
+	if (vgt->pdev->vgt_on_pipe[pipe] != vgt){
 		if (pipe == PIPE_A) {
 			event = PRIMARY_A_FLIP_DONE;
 		} else if (pipe == PIPE_B) {
diff --git a/drivers/gpu/drm/i915/vgt/sysfs.c b/drivers/gpu/drm/i915/vgt/sysfs.c
index 1c54890..98ccf97 100644
--- a/drivers/gpu/drm/i915/vgt/sysfs.c
+++ b/drivers/gpu/drm/i915/vgt/sysfs.c
@@ -522,6 +522,195 @@ static bool is_pport_present(struct pgt_device *pgt, struct gt_port *port)
 
 }
 
+static ssize_t vgt_pport_owner_show(struct kobject *kobj, struct kobj_attribute *attr,
+				   char *buf)
+{
+	struct pgt_device *pgt = &default_device;
+
+	//struct gt_port *port = kobj_to_port(kobj);
+	ssize_t buf_len;
+	enum vgt_pipe ppipe;
+	int i,j;
+    
+    for (i = 0; i < I915_MAX_PORTS; i++) {
+        if (strcmp(VGT_PORT_NAME(i), kobj->name) == 0) {
+                break;
+        }
+    }
+
+	if (i >= I915_MAX_PORTS) {
+		return 0;
+	}
+
+	mutex_lock(&vgt_sysfs_lock);
+
+    // if port A then check transcoder EDP
+    if (i == 0){
+    	ppipe = get_edp_input(VGT_MMIO_READ(pgt,_REG_TRANS_DDI_FUNC_CTL_EDP));
+    }
+    else{
+    	for (j = 0; j <= TRANSCODER_C; j++)
+        	if ((VGT_MMIO_READ(pgt,_VGT_TRANS_DDI_FUNC_CTL(j)) & 
+        			_REGBIT_TRANS_DDI_PORT_MASK) >> _TRANS_DDI_PORT_SHIFT == i)
+        		break;
+    }
+
+    if (j > TRANSCODER_C){
+        vgt_warn("port %s is not active\n", kobj->name);
+        buf_len = sprintf(buf, "port %s is not active\n", kobj->name);
+        goto out;
+    }
+
+    ppipe = j;
+
+    buf_len = sprintf(buf, "%d\n",pgt->vgt_on_pipe[ppipe]->vm_id);
+out:
+	mutex_unlock(&vgt_sysfs_lock);
+
+	return buf_len;
+}
+
+static ssize_t vgt_pport_owner_switch_store(struct kobject *kobj, struct kobj_attribute *attr,
+			const char *buf, size_t count);
+// show triggers switch to allow switching from non root
+static ssize_t vgt_pport_owner_switch_show(struct kobject *kobj, struct kobj_attribute *attr,
+				   char *buf)
+{
+	char one_char[5] = "1";
+	vgt_pport_owner_switch_store(kobj, attr, &one_char[0], 2);
+	return vgt_pport_owner_show(kobj, attr, buf);
+}
+
+static ssize_t vgt_pport_owner_store(struct kobject *kobj, struct kobj_attribute *attr,
+			const char *buf, size_t count)
+{
+	struct pgt_device *pgt = &default_device;
+	struct vgt_device *next_vgt;
+
+	//struct gt_port *port = kobj_to_port(kobj);
+	enum vgt_pipe ppipe;
+	int vmid,i,j;
+
+//	vgt_info("started");
+	if (sscanf(buf, "%d", &vmid) != 1)
+		return -EINVAL;
+    
+    for (i = PIPE_A; i < I915_MAX_PORTS; i++) {
+        if (strcmp(VGT_PORT_NAME(i), kobj->name) == 0) {
+                break;
+        }
+    }
+
+	if (i >= I915_MAX_PORTS) {
+		return 0;
+	}
+//	vgt_info("port found");
+	mutex_lock(&vgt_sysfs_lock);
+
+    // if port A then check transcoder EDP
+    if (i == PIPE_A){
+    	ppipe = get_edp_input(VGT_MMIO_READ(pgt,_REG_TRANS_DDI_FUNC_CTL_EDP));
+    }
+    else{
+    	for (j = 0; j <= TRANSCODER_C; j++)
+        	if ((VGT_MMIO_READ(pgt,_VGT_TRANS_DDI_FUNC_CTL(j)) & 
+        			_REGBIT_TRANS_DDI_PORT_MASK) >> _TRANS_DDI_PORT_SHIFT == i)
+        		break;
+    }
+
+    if (j > TRANSCODER_C){
+        vgt_warn("port %s is not active\n", kobj->name);
+        goto out;
+    }
+
+    ppipe = j;
+    next_vgt = vmid_2_vgt_device(vmid);
+
+    if (next_vgt == NULL || pgt->vgt_on_pipe[ppipe] == next_vgt){
+    	vgt_warn("can't switch port owner %s\n", kobj->name);
+    	goto out;
+    }
+
+    pgt->next_vgt_on_pipe[ppipe] = next_vgt;
+    vgt_raise_request(pgt, VGT_REQUEST_DPY_SWITCH);
+out:    
+    mutex_unlock(&vgt_sysfs_lock);
+
+	return count;
+}
+
+#define TMP_BUF_LEN 10
+static ssize_t vgt_pport_owner_switch_store(struct kobject *kobj, struct kobj_attribute *attr,
+			const char *buf, size_t count)
+{
+	struct pgt_device *pgt = &default_device;
+	struct vgt_device *next_vgt;
+
+	//struct gt_port *port = kobj_to_port(kobj);
+	enum vgt_pipe ppipe;
+	int sw_num,i,j;
+	char temp_buf[TMP_BUF_LEN];
+
+//	vgt_info("started");
+	if (sscanf(buf, "%d", &sw_num) != 1)
+		return -EINVAL;
+    
+    for (i = PORT_A; i < I915_MAX_PORTS; i++) {
+        if (strcmp(VGT_PORT_NAME(i), kobj->name) == 0) {
+                break;
+        }
+    }
+
+	if (i >= I915_MAX_PORTS || sw_num == 0) {
+		return 0;
+	}
+
+	if (i == PORT_A){ 
+    	ppipe = get_edp_input(VGT_MMIO_READ(pgt,_REG_TRANS_DDI_FUNC_CTL_EDP));
+    }
+    else{
+    	for (j = 0; j <= TRANSCODER_C; j++)
+        	if ((VGT_MMIO_READ(pgt,_VGT_TRANS_DDI_FUNC_CTL(j)) & 
+        			_REGBIT_TRANS_DDI_PORT_MASK) >> _TRANS_DDI_PORT_SHIFT == i)
+        		break;
+    }
+
+    if (j > TRANSCODER_C){
+        vgt_warn("pport %s is not active\n", kobj->name);
+        return 0;
+    }
+
+    ppipe = j;
+
+    for (i = 0; i< VGT_MAX_VMS; i++)
+    	if (pgt->device[i] == pgt->vgt_on_pipe[ppipe]) 
+    		break;
+
+	for (;; i = (i+1)% VGT_MAX_VMS){
+		next_vgt = pgt->device[i];
+		if (next_vgt != NULL) {
+			int k;
+			for(k = 0; k < I915_MAX_PIPES; k++)
+				if (next_vgt->pipe_mapping[k] == ppipe)
+					break;
+
+			if(sw_num == 0)
+				break;
+
+			sw_num = k==I915_MAX_PIPES ? sw_num : (sw_num-1);
+		}
+	}
+
+	if (sw_num != 0)
+		return 0;
+	sprintf(temp_buf, "%d", next_vgt->vm_id);
+
+	vgt_info("owner store call %d ", next_vgt->vm_id);
+	vgt_pport_owner_store(kobj, attr, &temp_buf[0], TMP_BUF_LEN);
+	return count;
+}
+
+
 static ssize_t vgt_pport_presnece_show(struct kobject *kobj, struct kobj_attribute *attr,
 				   char *buf)
 {
@@ -796,10 +985,18 @@ static struct kobj_attribute pport_connection_attrs =
 static struct kobj_attribute pport_presence_attrs =
 	__ATTR(presence, 0440, vgt_pport_presnece_show, NULL);
 
+static struct kobj_attribute pport_owner_attr =
+	__ATTR(owner, 0660, vgt_pport_owner_show, vgt_pport_owner_store);
+
+static struct kobj_attribute pport_owner_switch_attr =
+	__ATTR(owner_switch, 0664, vgt_pport_owner_switch_show, vgt_pport_owner_switch_store);
+
 static struct attribute *vgt_pport_attrs[] = {
 	&pport_connection_attrs.attr,
 	&pport_type_attrs.attr,
 	&pport_presence_attrs.attr,
+	&pport_owner_attr.attr,
+	&pport_owner_switch_attr.attr,
 	NULL,
 };
 
diff --git a/drivers/gpu/drm/i915/vgt/vgt.c b/drivers/gpu/drm/i915/vgt/vgt.c
index 2625e59..406e9b0 100644
--- a/drivers/gpu/drm/i915/vgt/vgt.c
+++ b/drivers/gpu/drm/i915/vgt/vgt.c
@@ -708,6 +708,7 @@ static int vgt_initialize(struct pci_dev *dev)
 	struct pgt_device *pdev = &default_device;
 	struct task_struct *p_thread;
 	vgt_params_t vp;
+	int i;
 
 	spin_lock_init(&pdev->lock);
 
@@ -756,6 +757,12 @@ static int vgt_initialize(struct pci_dev *dev)
 		vgt_ctx_switch = 0;
 
 	current_foreground_vm(pdev) = vgt_dom0;
+
+    for (i = 0; i < I915_MAX_PIPES; i++){
+            pdev->vgt_on_pipe[i] = vgt_dom0;
+            pdev->next_vgt_on_pipe[i] = NULL;
+    }
+
 	if (!hvm_display_owner) {
 		current_display_owner(pdev) = vgt_dom0;
 	}
diff --git a/drivers/gpu/drm/i915/vgt/vgt.h b/drivers/gpu/drm/i915/vgt/vgt.h
index 0b688c7..75f01ae 100644
--- a/drivers/gpu/drm/i915/vgt/vgt.h
+++ b/drivers/gpu/drm/i915/vgt/vgt.h
@@ -1210,6 +1210,8 @@ struct pgt_device {
 	struct vgt_device *foreground_vm;		/* current visible domain on display. */
 	struct vgt_device *next_sched_vgt;
 	struct vgt_device *next_foreground_vm;
+	struct vgt_device *vgt_on_pipe[I915_MAX_PIPES];
+	struct vgt_device *next_vgt_on_pipe[I915_MAX_PIPES];
 	struct list_head rendering_runq_head; /* reuse this for context scheduler */
 	struct list_head rendering_idleq_head; /* reuse this for context scheduler */
 	spinlock_t lock;
@@ -1344,6 +1346,7 @@ static inline void vgt_panic(void)
 
 	dump_stack();
 	printk("________end of stack dump_________\n");
+
 	panic("FATAL VGT ERROR\n");
 }
 #define ASSERT(x)							\
@@ -3068,7 +3071,13 @@ static inline bool hypervisor_write_va(struct vgt_device *vgt, void *va,
 			if (atomic_cmpxchg(&(vgt)->crashing, 0, 1))	\
 				break;					\
 			vgt_warn("Killing VM%d\n", (vgt)->vm_id);	\
-			if (!hypervisor_pause_domain((vgt)))		\
+		/*	if (vgt->vm_id == 0)   {                     \
+				dump_stack();								\
+				printk("________end of stack dump_________\n");\
+				while(1) {vgt->vm_id++; 		\
+					if (vgt->vm_id==1000000000) break;}			\
+			}\
+		*/	if (!hypervisor_pause_domain((vgt)))		\
 				hypervisor_shutdown_domain((vgt));	\
 		}							\
 	} while (0)
-- 
1.9.1


From ad442e81b88d28ee371d893452b1804c51358135 Mon Sep 17 00:00:00 2001
From: Konstantin Anisimov <rrevenantt@gmail.com>
Date: Thu, 21 May 2015 14:41:14 +0300
Subject: [PATCH 2/3] some buggy changes. To start new brach

---
 drivers/gpu/drm/i915/vgt/debugfs.c  |  30 ++++
 drivers/gpu/drm/i915/vgt/display.c  |  45 +++--
 drivers/gpu/drm/i915/vgt/handlers.c | 320 +++++++++++++++++++++++++-----------
 drivers/gpu/drm/i915/vgt/mmio.c     |  14 ++
 drivers/gpu/drm/i915/vgt/reg.h      |  43 +++++
 drivers/gpu/drm/i915/vgt/sysfs.c    |  49 ++++--
 drivers/gpu/drm/i915/vgt/vgt.c      |  10 +-
 drivers/gpu/drm/i915/vgt/vgt.h      |   1 +
 8 files changed, 383 insertions(+), 129 deletions(-)

diff --git a/drivers/gpu/drm/i915/vgt/debugfs.c b/drivers/gpu/drm/i915/vgt/debugfs.c
index a51dfa4..78cc0f3 100644
--- a/drivers/gpu/drm/i915/vgt/debugfs.c
+++ b/drivers/gpu/drm/i915/vgt/debugfs.c
@@ -703,11 +703,36 @@ static int vgt_show_virt_dpyinfo(struct seq_file *m, void *data)
 	return 0;
 }
 
+static int vgt_show_phys_vgt_on_pipe(struct seq_file *m, void *data)
+{
+	struct pgt_device *pdev =  (struct pgt_device *)m->private;
+	enum vgt_pipe pipe;
+
+	for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) {
+		seq_printf(m,"pipe %d vm : %d\n", pipe, pdev->vgt_on_pipe[pipe]->vm_id);
+
+	}
+
+	return 0;
+}
+
 static int vgt_phys_dpyinfo_open(struct inode *inode, struct file *file)
 {
 	return single_open(file, vgt_show_phys_dpyinfo, inode->i_private);
 }
 
+static int vgt_phys_vgt_on_pipe_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, vgt_show_phys_vgt_on_pipe, inode->i_private);
+}
+
+static const struct file_operations phys_vgt_on_pipe_fops = {
+	.open = vgt_phys_vgt_on_pipe_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
+};
+
 static const struct file_operations phys_dpyinfo_fops = {
 	.open = vgt_phys_dpyinfo_open,
 	.read = seq_read,
@@ -975,6 +1000,11 @@ struct dentry *vgt_init_debugfs(struct pgt_device *pdev)
 	if (!temp_d)
 		return NULL;
 
+	temp_d = debugfs_create_file("vgt_on_pipe", 0444, d_vgt_debug,
+		pdev, &phys_vgt_on_pipe_fops);
+	if (!temp_d)
+		return NULL;
+
 	return d_vgt_debug;
 }
 
diff --git a/drivers/gpu/drm/i915/vgt/display.c b/drivers/gpu/drm/i915/vgt/display.c
index 06712f9..08ca7a7 100644
--- a/drivers/gpu/drm/i915/vgt/display.c
+++ b/drivers/gpu/drm/i915/vgt/display.c
@@ -118,14 +118,40 @@ int prepare_for_display_switch(struct pgt_device *pdev)
  */
 void do_vgt_fast_display_switch(struct pgt_device *pdev)
 {
-	struct vgt_device *to_vgt = pdev->next_foreground_vm;
+	struct vgt_device *to_vgt;
 	enum vgt_pipe pipe;
 
-	vgt_dbg(VGT_DBG_DPY, "vGT: doing display switch: from %p to %p\n",
-			current_foreground_vm(pdev), to_vgt);
+//	vgt_dbg(VGT_DBG_DPY, "vGT: doing display switch: from %p to %p\n",
+//			current_foreground_vm(pdev), to_vgt);
+
+	//vgt_info("debug\n");
 
 	ASSERT(fastpath_dpy_switch);
 	ASSERT(spin_is_locked(&pdev->lock));
+
+	for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) 
+		if (pdev->next_vgt_on_pipe[pipe] != NULL ){
+			enum vgt_pipe vpipe;
+			to_vgt = pdev->next_vgt_on_pipe[pipe];
+			vgt_info("debug %d\n",vpipe);
+			for (vpipe = PIPE_A; vpipe < I915_MAX_PIPES; vpipe++){
+//				vgt_info("vgt %d, ppipe %d,vpipe %d,reg %x",to_vgt->vm_id,pipe,vpipe,__vreg(to_vgt, VGT_DSPCNTR(vpipe)));
+				if (to_vgt->pipe_mapping[vpipe] == pipe 
+					&& (_PRI_PLANE_ENABLE & __vreg(to_vgt, VGT_DSPCNTR(vpipe))))
+					break;
+			}
+
+			if(vpipe >= I915_MAX_PIPES)
+				continue;
+
+			pdev->vgt_on_pipe[pipe] = to_vgt;
+			vgt_info("switching vgt %d on ppipe %s\n",to_vgt->vm_id,VGT_PIPE_NAME(pipe));
+			vgt_restore_state(to_vgt, vpipe);
+			set_panel_fitting(to_vgt, vpipe);
+			pdev->next_vgt_on_pipe[pipe] = NULL;				
+		}
+
+	to_vgt = pdev->next_foreground_vm;
 	if (to_vgt != current_foreground_vm(pdev)){
 		for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) 
 			if (_PRI_PLANE_ENABLE & __vreg(to_vgt, VGT_DSPCNTR(pipe))) {
@@ -135,18 +161,7 @@ void do_vgt_fast_display_switch(struct pgt_device *pdev)
 				
 			}
 		current_foreground_vm(pdev) = to_vgt;
-		
-	} else
-	for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) {
-		if (pdev->next_vgt_on_pipe[pipe] != NULL 
-			&& _PRI_PLANE_ENABLE & __vreg(pdev->next_vgt_on_pipe[pipe], VGT_DSPCNTR(pipe))){
-			pdev->vgt_on_pipe[pipe] = pdev->next_vgt_on_pipe[pipe];
-			vgt_restore_state(pdev->next_vgt_on_pipe[pipe], pipe);
-			set_panel_fitting(pdev->next_vgt_on_pipe[pipe], pipe);
-			pdev->next_vgt_on_pipe[pipe] = NULL;				
-		}
-	}
-
+	} 
 	
 }
 
diff --git a/drivers/gpu/drm/i915/vgt/handlers.c b/drivers/gpu/drm/i915/vgt/handlers.c
index 80b7182..5fca786 100644
--- a/drivers/gpu/drm/i915/vgt/handlers.c
+++ b/drivers/gpu/drm/i915/vgt/handlers.c
@@ -1245,7 +1245,13 @@ bool vgt_map_plane_reg(struct vgt_device *vgt, unsigned int reg, unsigned int *p
 	return true;
 
 }
-
+static bool dpy_palette_mmio_read(struct vgt_device *vgt, unsigned int offset,
+			void *p_data, unsigned int bytes)
+{
+	*(vgt_reg_t *)p_data = __vreg(vgt, offset);
+	vgt_warn("palette read ?? !!!!!!!!");
+	return true;
+}
 static bool dpy_plane_mmio_read(struct vgt_device *vgt, unsigned int offset,
 			void *p_data, unsigned int bytes)
 {
@@ -1255,6 +1261,43 @@ static bool dpy_plane_mmio_read(struct vgt_device *vgt, unsigned int offset,
 	return true;
 }
 
+static bool dpy_palette_mmio_write(struct vgt_device *vgt, unsigned int offset,
+	void *p_data, unsigned int bytes)
+{
+	unsigned int real_offset;
+	int vpipe = (offset & _REG_PALETTE_TO_PIPE_MASK) >> _REG_PALETTE_TO_PIPE_OFFSET;
+	int ppipe = vgt->pipe_mapping[vpipe];
+
+	real_offset = offset - _REG_PALETTE_TO_PIPE_MASK * vpipe + _REG_PALETTE_TO_PIPE_MASK * ppipe;
+
+	memcpy ((char *)vgt->state.vReg + offset, p_data, bytes);
+	memcpy ((char *)vgt->state.sReg + offset, p_data, bytes);
+
+	if (vgt->pdev->vgt_on_pipe[vgt->pipe_mapping[vpipe]] == vgt){
+			VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+	}
+	return true;
+}
+
+static bool dpy_csc_mmio_write(struct vgt_device *vgt, unsigned int offset,
+	void *p_data, unsigned int bytes)
+{
+//	unsigned int real_offset;
+//	int vpipe = (offset & _REG_CSC_TO_PIPE_MASK) >> _REG_CSC_TO_PIPE_SHIFT;
+//	int ppipe = vgt->pipe_mapping[vpipe];
+//
+//	real_offset = offset - _REG_CSC_TO_PIPE_MASK * vpipe + _REG_CSC_TO_PIPE_MASK * ppipe;
+//
+	default_mmio_write(vgt, offset, p_data, bytes);
+//	memcpy ((char *)vgt->state.vReg + offset, p_data, bytes);
+//	memcpy ((char *)vgt->state.sReg + offset, p_data, bytes);
+//
+//	if (vgt->pdev->vgt_on_pipe[vgt->pipe_mapping[vpipe]] == vgt){
+//			VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+//	}
+	return true;
+}
+
 static bool dpy_plane_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	void *p_data, unsigned int bytes)
 {
@@ -1273,6 +1316,62 @@ static bool dpy_plane_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	return true;
 }
 
+//static unsigned int transcoder_remapping(struct vgt_device *vgt, unsigned int vtrans)
+//{
+//	unsigned int ppipe, vpipe, ptrans;
+//
+//	if( vtrans == TRANSCODER_EDP
+//		&& __vreg(vgt,_REG_TRANS_DDI_FUNC_CTL_EDP) & _REGBIT_TRANS_DDI_FUNC_ENABLE){
+//		vpipe = get_edp_input(__vreg(vgt,_REG_TRANS_DDI_FUNC_CTL_EDP));
+//	}
+//	else
+//		vpipe = vtrans;
+//
+//	ppipe = vgt->pipe_mapping[vpipe];
+//	if (ppipe == I915_MAX_PIPES)
+//		return -1;
+//
+//	if(VGT_MMIO_READ(vgt->pdev,_REG_TRANS_DDI_FUNC_CTL_EDP) & _REGBIT_TRANS_DDI_FUNC_ENABLE){
+//		if (ppipe == get_edp_input(VGT_MMIO_READ(vgt->pdev,_REG_TRANS_DDI_FUNC_CTL_EDP))){
+//			ptrans = TRANSCODER_EDP;
+//		}
+//	}
+//	else{
+//		ptrans = ppipe;
+//	}
+//
+//	return ptrans;
+//}
+
+//static bool dpy_trans_remap_mmio_read(struct vgt_device *vgt, unsigned int offset,
+//	void *p_data, unsigned int bytes)
+//{
+//	*(vgt_reg_t *)p_data = __vreg(vgt, offset);
+//
+//	return true;
+//}
+
+static bool dpy_trans_remap_mmio_write(struct vgt_device *vgt, unsigned int offset,
+	void *p_data, unsigned int bytes)
+{
+//	unsigned int real_offset;
+//	unsigned int vtrans = (offset & _REGBIT_REG_TRANS_MASK) >> _REGBIT_REG_TRANS_SHIFT;
+//	unsigned int ptrans;
+
+	default_mmio_write(vgt, offset, p_data, bytes);
+//	memcpy ((char *)vgt->state.vReg + offset, p_data, bytes);
+//	memcpy ((char *)vgt->state.sReg + offset, p_data, bytes);
+//
+//	ptrans = transcoder_remapping(vgt, vtrans);
+//	if (ptrans < 0)
+//		return true;
+//
+//	real_offset = (offset & ~_REGBIT_REG_TRANS_MASK) | ptrans << _REGBIT_REG_TRANS_SHIFT;
+//	VGT_MMIO_WRITE(vgt->pdev, real_offset, __sreg(vgt, offset));
+
+	return true;
+}
+
 static bool dpy_plane_ctl_write(struct vgt_device *vgt, unsigned int offset,
 	void *p_data, unsigned int bytes)
 {
@@ -1292,12 +1391,12 @@ static bool dpy_plane_ctl_write(struct vgt_device *vgt, unsigned int offset,
 
 	dpy_plane_mmio_write(vgt, offset, p_data, bytes);
 	if (enable_plane) {
-		if (current_foreground_vm(vgt->pdev) == vgt) {
-//		if (vgt->pdev->vgt_on_pipe == vgt){
+//		if (current_foreground_vm(vgt->pdev) == vgt) {
+		if (vgt->pdev->vgt_on_pipe[vgt->pipe_mapping[pipe]] == vgt){
 			set_panel_fitting(vgt, pipe);
 		} else if (is_current_display_owner(vgt)) {
 			p_pipe = vgt->pipe_mapping[pipe];
-			foreground_vgt = current_foreground_vm(vgt->pdev);
+			foreground_vgt = vgt->pdev->vgt_on_pipe[p_pipe];//current_foreground_vm(vgt->pdev);
 			for (i = 0; i < I915_MAX_PIPES; i++) {
 				if (foreground_vgt->pipe_mapping[i] == p_pipe) {
 					v_pipe = i;
@@ -2756,10 +2855,18 @@ reg_attr_t vgt_base_reg_info[] = {
 {_REG_CURASURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_ALL, cur_surflive_mmio_read,
 					surflive_mmio_write},
 
-{_REG_CURAPALET_0, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_CURAPALET_1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_CURAPALET_2, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_CURAPALET_3, 4, F_DPY, 0, D_ALL, NULL, NULL},
+{_REG_CURAPALET_0, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURAPALET_1, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURAPALET_2, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURAPALET_3, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURBPALET_0, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURBPALET_1, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURBPALET_2, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURBPALET_3, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURCPALET_0, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURCPALET_1, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURCPALET_2, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURCPALET_3, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
 
 {_REG_CURBBASE_SNB, 4, F_DPY_ADRFIX, 0xFFFFF000, D_SNB, dpy_plane_mmio_read,
 						dpy_plane_mmio_write},
@@ -2897,81 +3004,107 @@ reg_attr_t vgt_base_reg_info[] = {
 {_REG_SPRC_SCALE, 4, F_DPY, 0, D_HSW, NULL, NULL},
 
 
-{_REG_LGC_PALETTE_A, 4*256, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_LGC_PALETTE_B, 4*256, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_LGC_PALETTE_C, 4*256, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
+{_REG_LGC_PALETTE_A, 4*256, /*F_DPY*/ F_VIRT, 0, D_ALL, dpy_palette_mmio_read, dpy_palette_mmio_write},
+{_REG_LGC_PALETTE_B, 4*256, /*F_DPY*/ F_VIRT, 0, D_ALL, dpy_palette_mmio_read, dpy_palette_mmio_write},
+{_REG_LGC_PALETTE_C, 4*256, /*F_DPY*/ F_VIRT, 0, D_GEN7PLUS, dpy_palette_mmio_read, dpy_palette_mmio_write},
+
+{_REG_PIPE_PAL_GC_MAX_A, 4*3, /*F_DPY*/ F_VIRT, 0, D_ALL, dpy_palette_mmio_read, dpy_palette_mmio_write},
+{_REG_PIPE_PAL_GC_MAX_B, 4*3, /*F_DPY*/ F_VIRT, 0, D_ALL, dpy_palette_mmio_read, dpy_palette_mmio_write},
+{_REG_PIPE_PAL_GC_MAX_C, 4*3, /*F_DPY*/ F_VIRT, 0, D_GEN7PLUS, dpy_palette_mmio_read, dpy_palette_mmio_write},
+
+{_REG_PIPE_PAL_EXT_GC_MAX_A, 4*3, /*F_DPY*/ F_VIRT, 0, D_ALL, dpy_palette_mmio_read, dpy_palette_mmio_write},
+{_REG_PIPE_PAL_EXT_GC_MAX_B, 4*3, /*F_DPY*/ F_VIRT, 0, D_ALL, dpy_palette_mmio_read, dpy_palette_mmio_write},
+{_REG_PIPE_PAL_EXT_GC_MAX_C, 4*3, /*F_DPY*/ F_VIRT, 0, D_GEN7PLUS, dpy_palette_mmio_read, dpy_palette_mmio_write},
 
-{_REG_HTOTAL_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HBLANK_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HSYNC_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VTOTAL_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VBLANK_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VSYNC_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
+{_REG_PIPE_PAL_PREC_A, 4, /*F_DPY*/ F_VIRT, 0, D_ALL, dpy_palette_mmio_read, dpy_palette_mmio_write},
+{_REG_PIPE_PAL_PREC_B, 4, /*F_DPY*/ F_VIRT, 0, D_ALL, dpy_palette_mmio_read, dpy_palette_mmio_write},
+{_REG_PIPE_PAL_PREC_C, 4, /*F_DPY*/ F_VIRT, 0, D_GEN7PLUS, dpy_palette_mmio_read, dpy_palette_mmio_write},
+
+{_REG_PIPE_PAL_PREC_DATA_A, 4, /*F_DPY*/ F_VIRT, 0, D_ALL, dpy_palette_mmio_read, dpy_palette_mmio_write},
+{_REG_PIPE_PAL_PREC_DATA_B, 4, /*F_DPY*/ F_VIRT, 0, D_ALL, dpy_palette_mmio_read, dpy_palette_mmio_write},
+{_REG_PIPE_PAL_PREC_DATA_C, 4, /*F_DPY*/ F_VIRT, 0, D_GEN7PLUS, dpy_palette_mmio_read, dpy_palette_mmio_write},
+
+{_REG_HTOTAL_A, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_HBLANK_A, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_HSYNC_A, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_VTOTAL_A, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_VBLANK_A, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_VSYNC_A, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
 {_REG_PIPEASRC, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
 {_REG_BCLRPAT_A, 4, F_DPY, 0, D_ALL, NULL, NULL},
 {_REG_VSYNCSHIFT_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
 
-{_REG_HTOTAL_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HBLANK_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HSYNC_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VTOTAL_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VBLANK_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VSYNC_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
+{_REG_HTOTAL_B, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_HBLANK_B, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_HSYNC_B, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_VTOTAL_B, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_VBLANK_B, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_VSYNC_B, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
 {_REG_PIPEBSRC, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
 {_REG_BCLRPAT_B, 4, F_DPY, 0, D_ALL, NULL, NULL},
 {_REG_VSYNCSHIFT_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
 
-{_REG_HTOTAL_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HBLANK_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HSYNC_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VTOTAL_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VBLANK_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VSYNC_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
+{_REG_HTOTAL_C, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_HBLANK_C, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_HSYNC_C, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_VTOTAL_C, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_VBLANK_C, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_VSYNC_C, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
 {_REG_PIPECSRC, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
 {_REG_BCLRPAT_C, 4, F_DPY, 0, D_ALL, NULL, NULL},
 {_REG_VSYNCSHIFT_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
 
-{0x6F000, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F004, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F008, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F00C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F010, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F014, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F028, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
+{0x6F000, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{0x6F004, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{0x6F008, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{0x6F00C, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{0x6F010, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{0x6F014, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{0x6F028, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
 {0x6F030, 4, F_DPY, 0, D_ALL, NULL, NULL},
 {0x6F034, 4, F_DPY, 0, D_ALL, NULL, NULL},
 {0x6F040, 4, F_DPY, 0, D_ALL, NULL, NULL},
 {0x6F044, 4, F_DPY, 0, D_ALL, NULL, NULL},
 
-{_REG_PIPEA_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEA_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEA_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEA_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-
-{_REG_PIPEA_DATA_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-{_REG_PIPEA_DATA_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-{_REG_PIPEA_LINK_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-{_REG_PIPEA_LINK_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-
-{_REG_PIPEB_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEB_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEB_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEB_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-
-{_REG_PIPEB_DATA_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-{_REG_PIPEB_DATA_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-{_REG_PIPEB_LINK_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-{_REG_PIPEB_LINK_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-
-{_REG_PIPEC_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEC_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEC_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEC_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-
-{_REG_PIPEC_DATA_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-{_REG_PIPEC_DATA_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-{_REG_PIPEC_LINK_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
-{_REG_PIPEC_LINK_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
+{_REG_PIPEA_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEA_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEA_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEA_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+
+{_REG_PIPEA_DATA_M2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEA_DATA_N2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEA_LINK_M2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEA_LINK_N2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+
+{_REG_PIPEB_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEB_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEB_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEB_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+
+{_REG_PIPEB_DATA_M2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEB_DATA_N2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEB_LINK_M2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEB_LINK_N2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+
+{_REG_PIPEC_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEC_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEC_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEC_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+
+{_REG_PIPEC_DATA_M2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEC_DATA_N2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEC_LINK_M2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+{_REG_PIPEC_LINK_N2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+
+//{_REG_PIPE_EDP_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+//{_REG_PIPE_EDP_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+//{_REG_PIPE_EDP_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+//{_REG_PIPE_EDP_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, dpy_trans_remap_mmio_write},
+//
+//{_REG_PIPE_EDP_DATA_M2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+//{_REG_PIPE_EDP_DATA_N2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+//{_REG_PIPE_EDP_LINK_M2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
+//{_REG_PIPE_EDP_LINK_N2, 4, F_DPY, 0, D_IVB, NULL, dpy_trans_remap_mmio_write},
 
 {_REG_PF_CTL_0, 4, F_DPY, 0, D_ALL, pf_read, pf_write},
 {_REG_PF_WIN_SZ_0, 4, F_DPY, 0, D_ALL, pf_read, pf_write},
@@ -3136,23 +3269,26 @@ reg_attr_t vgt_base_reg_info[] = {
 {_REG_DPFC_CONTROL_SA, 4, F_VIRT, 0, D_ALL, NULL, NULL},
 {_REG_DPFC_CPU_FENCE_OFFSET_SA, 4, F_VIRT, 0, D_ALL, NULL, NULL},
 
-{_REG_CSC_A_COEFFICIENTS, 4*6, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_CSC_A_MODE, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PRECSC_A_HIGH_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PRECSC_A_MEDIUM_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PRECSC_A_LOW_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, NULL},
-
-{_REG_CSC_B_COEFFICIENTS, 4*6, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_CSC_B_MODE, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PRECSC_B_HIGH_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PRECSC_B_MEDIUM_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PRECSC_B_LOW_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, NULL},
-
-{_REG_CSC_C_COEFFICIENTS, 4*6, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-{_REG_CSC_C_MODE, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-{_REG_PRECSC_C_HIGH_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-{_REG_PRECSC_C_MEDIUM_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-{_REG_PRECSC_C_LOW_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
+{_REG_CSC_A_COEFFICIENTS, 4*6, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+{_REG_CSC_A_MODE, 4, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_A_HIGH_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_A_MEDIUM_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_A_LOW_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_A_POST_OFFSET, 4*3, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+
+{_REG_CSC_B_COEFFICIENTS, 4*6, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+{_REG_CSC_B_MODE, 4, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_B_HIGH_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_B_MEDIUM_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_B_LOW_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_B_POST_OFFSET, 4*3, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
+
+{_REG_CSC_C_COEFFICIENTS, 4*6, F_DPY, 0, D_GEN7PLUS, NULL, dpy_csc_mmio_write},
+{_REG_CSC_C_MODE, 4, F_DPY, 0, D_GEN7PLUS, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_C_HIGH_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_GEN7PLUS, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_C_MEDIUM_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_GEN7PLUS, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_C_LOW_COLOR_CHANNEL_OFFSET, 4, F_DPY, 0, D_GEN7PLUS, NULL, dpy_csc_mmio_write},
+{_REG_PRECSC_C_POST_OFFSET, 4*3, F_DPY, 0, D_ALL, NULL, dpy_csc_mmio_write},
 
 {0x60110, 4, F_DPY, 0, D_ALL, NULL, NULL},
 {0x61110, 4, F_DPY, 0, D_ALL, NULL, NULL},
@@ -3185,28 +3321,28 @@ reg_attr_t vgt_base_reg_info[] = {
 {_REG_TRANS_CLK_SEL_C, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x46408, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x46508, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
-{0x49040, 0xc, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
-{0x49140, 0xc, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
-{0x49240, 0xc, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
+//{0x49040, 0xc, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
+//{0x49140, 0xc, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
+//{0x49240, 0xc, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x49080, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x49090, 0x14, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x49180, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x49190, 0x14, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x49280, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x49290, 0x14, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
-{0x4A400, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
+//{0x4A400, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x4A480, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
-{0x4AC00, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
+//{0x4AC00, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x4AC80, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
-{0x4B400, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
+//{0x4B400, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 {0x4B480, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 
 {0x6002C, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
 
-{_REG_HSW_VIDEO_DIP_CTL_A, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
-{_REG_HSW_VIDEO_DIP_CTL_B, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
-{_REG_HSW_VIDEO_DIP_CTL_C, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
-{_REG_HSW_VIDEO_DIP_CTL_EDP, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
+{_REG_HSW_VIDEO_DIP_CTL_A, 4, F_DPY, 0, D_HSW_PLUS, NULL, dpy_trans_remap_mmio_write},
+{_REG_HSW_VIDEO_DIP_CTL_B, 4, F_DPY, 0, D_HSW_PLUS, NULL, dpy_trans_remap_mmio_write},
+{_REG_HSW_VIDEO_DIP_CTL_C, 4, F_DPY, 0, D_HSW_PLUS, NULL, dpy_trans_remap_mmio_write},
+{_REG_HSW_VIDEO_DIP_CTL_EDP, 4, F_DPY, 0, D_HSW_PLUS, NULL, dpy_trans_remap_mmio_write},
 
 {_REG_SFUSE_STRAP, 4, F_DPY, 0, D_HSW_PLUS, sfuse_strap_mmio_read, NULL},
 {_REG_SBI_ADDR, 4, F_DPY, 0, D_HSW_PLUS, NULL, NULL},
diff --git a/drivers/gpu/drm/i915/vgt/mmio.c b/drivers/gpu/drm/i915/vgt/mmio.c
index 61676efe..532fad5 100644
--- a/drivers/gpu/drm/i915/vgt/mmio.c
+++ b/drivers/gpu/drm/i915/vgt/mmio.c
@@ -275,6 +275,7 @@ bool vgt_emulate_read(struct vgt_device *vgt, uint64_t pa, void *p_data,int byte
 	cycles_t t0, t1;
 	struct vgt_statistics *stat = &vgt->stat;
 	int cpu;
+	enum vgt_owner_type type;
 
 	t0 = get_cycles();
 
@@ -310,6 +311,12 @@ bool vgt_emulate_read(struct vgt_device *vgt, uint64_t pa, void *p_data,int byte
 	if (!reg_is_mmio(pdev, offset + bytes))
 		goto err_mmio;
 
+	type = vgt->pdev->reg_info[REG_INDEX(offset)] & VGT_REG_OWNER;
+//	if ((type & VGT_OT_DISPLAY) != 0)
+//		vgt_info("vGT: display reg MMIO read: vm_id(%d), offset=0x%x,"
+//			"len=%d, val=0x%x!!!\n",
+//			vgt->vm_id, offset, bytes, *(u32 *)p_data);
+
 	mht = vgt_find_mmio_entry(offset);
 	if ( mht && mht->read ) {
 		if (!valid_mmio_alignment(mht, offset, bytes))
@@ -371,6 +378,7 @@ bool vgt_emulate_write(struct vgt_device *vgt, uint64_t pa,
 	bool rc;
 	cycles_t t0, t1;
 	struct vgt_statistics *stat = &vgt->stat;
+	enum vgt_owner_type type;
 
 	vgt_lock_dev_flags(pdev, cpu, flags);
 
@@ -425,6 +433,12 @@ bool vgt_emulate_write(struct vgt_device *vgt, uint64_t pa,
 		//WARN_ON(vgt->vm_id == 0); /* The call stack is meaningless for HVM */
 	}
 
+	type = vgt->pdev->reg_info[REG_INDEX(offset)] & VGT_REG_OWNER;
+//	if ((type & VGT_OT_DISPLAY) != 0 && vgt->vm_id != 0)
+//		vgt_info("vGT: display reg MMIO write: vm_id(%d), offset=0x%x,"
+//			"len=%d, val=0x%x!!!\n",
+//			vgt->vm_id, offset, bytes, *(u32 *)p_data);
+
 	mht = vgt_find_mmio_entry(offset);
 	if ( mht && mht->write ) {
 		if (!valid_mmio_alignment(mht, offset, bytes))
diff --git a/drivers/gpu/drm/i915/vgt/reg.h b/drivers/gpu/drm/i915/vgt/reg.h
index 50dad26..8a4d7d8 100644
--- a/drivers/gpu/drm/i915/vgt/reg.h
+++ b/drivers/gpu/drm/i915/vgt/reg.h
@@ -355,6 +355,14 @@ static inline uint32_t __RING_REG(int32_t ring_id, uint32_t rcs_reg)
 #define _REG_CURAPALET_1	0x70094
 #define _REG_CURAPALET_2	0x70098
 #define _REG_CURAPALET_3	0x7009C
+#define _REG_CURBPALET_0	0x71090
+#define _REG_CURBPALET_1	0x71094
+#define _REG_CURBPALET_2	0x71098
+#define _REG_CURBPALET_3	0x7109C
+#define _REG_CURCPALET_0	0x72090
+#define _REG_CURCPALET_1	0x72094
+#define _REG_CURCPALET_2	0x72098
+#define _REG_CURCPALET_3	0x7209C
 
 #define _REG_CURBCNTR_SNB	0x700C0
 #define _REG_CURBBASE_SNB	0x700C4
@@ -871,6 +879,16 @@ static inline uint32_t __RING_REG(int32_t ring_id, uint32_t rcs_reg)
 #define _REG_PIPEC_LINK_M2		0x62048
 #define _REG_PIPEC_LINK_N2		0x6204c
 
+#define _REG_PIPE_EDP_DATA_M1		0x6f030
+#define _REG_PIPE_EDP_DATA_N1		0x6f034
+#define _REG_PIPE_EDP_LINK_M1		0x6f040
+#define _REG_PIPE_EDP_LINK_N1		0x6f044
+
+#define _REG_PIPE_EDP_DATA_M2		0x6f038
+#define _REG_PIPE_EDP_DATA_N2		0x6f03c
+#define _REG_PIPE_EDP_LINK_M2		0x6f048
+#define _REG_PIPE_EDP_LINK_N2		0x6f04c
+
 #define VGT_PIPE_DATA_M1(pipe) _VGT_PIPE(pipe, _REG_PIPEA_DATA_M1, _REG_PIPEB_DATA_M1)
 #define VGT_PIPE_DATA_N1(pipe) _VGT_PIPE(pipe, _REG_PIPEA_DATA_N1, _REG_PIPEB_DATA_N1)
 #define VGT_PIPE_DATA_M2(pipe) _VGT_PIPE(pipe, _REG_PIPEA_DATA_M2, _REG_PIPEB_DATA_M2)
@@ -1289,6 +1307,24 @@ union _TRANS_CONFIG
 #define _REG_LGC_PALETTE_B		0x4a800
 #define _REG_LGC_PALETTE_C		0x4b000
 #define VGT_LGC_PALETTE(pipe) _VGT_PIPE(pipe, _REG_LGC_PALETTE_A, _REG_LGC_PALETTE_B)
+#define _REG_PALETTE_TO_PIPE_MASK 0x01800
+#define _REG_PALETTE_TO_PIPE_OFFSET 11
+
+#define _REG_PIPE_PAL_PREC_A			0x4a400
+#define _REG_PIPE_PAL_PREC_DATA_A		0x4a404
+#define _REG_PIPE_PAL_GC_MAX_A			0x4a410
+#define _REG_PIPE_PAL_EXT_GC_MAX_A		0x4a420
+
+#define _REG_PIPE_PAL_PREC_B			0x4ac00
+#define _REG_PIPE_PAL_PREC_DATA_B		0x4ac04
+#define _REG_PIPE_PAL_GC_MAX_B			0x4ac10
+#define _REG_PIPE_PAL_EXT_GC_MAX_B		0x4ac20
+
+#define _REG_PIPE_PAL_PREC_C			0x4b400
+#define _REG_PIPE_PAL_PREC_DATA_C		0x4b404
+#define _REG_PIPE_PAL_GC_MAX_C			0x4b410
+#define _REG_PIPE_PAL_EXT_GC_MAX_C		0x4b420
+
 
 /* Display Port */
 #define _REG_DP_TP_CTL_A		0x64040
@@ -1407,18 +1443,23 @@ union _TRANS_CONFIG
 #define _REG_PRECSC_A_HIGH_COLOR_CHANNEL_OFFSET		0x49030
 #define _REG_PRECSC_A_MEDIUM_COLOR_CHANNEL_OFFSET	0x49034
 #define _REG_PRECSC_A_LOW_COLOR_CHANNEL_OFFSET		0x49038
+#define _REG_PRECSC_A_POST_OFFSET		0x49040
 
 #define _REG_CSC_B_COEFFICIENTS		0x49110
 #define _REG_CSC_B_MODE			0x49128
 #define _REG_PRECSC_B_HIGH_COLOR_CHANNEL_OFFSET		0x49130
 #define _REG_PRECSC_B_MEDIUM_COLOR_CHANNEL_OFFSET	0x49134
 #define _REG_PRECSC_B_LOW_COLOR_CHANNEL_OFFSET		0x49138
+#define _REG_PRECSC_B_POST_OFFSET		0x49140
 
 #define _REG_CSC_C_COEFFICIENTS		0x49210
 #define _REG_CSC_C_MODE			0x49228
 #define _REG_PRECSC_C_HIGH_COLOR_CHANNEL_OFFSET		0x49230
 #define _REG_PRECSC_C_MEDIUM_COLOR_CHANNEL_OFFSET	0x49234
 #define _REG_PRECSC_C_LOW_COLOR_CHANNEL_OFFSET		0x49238
+#define _REG_PRECSC_C_POST_OFFSET		0x49240
+#define _REG_CSC_TO_PIPE_SHIFT 		8
+#define _REG_CSC_TO_PIPE_MASK  		(3<<_REG_CSC_TO_PIPE_SHIFT)
 
 /*
  * Instruction and interrupt control regs
@@ -1826,6 +1867,8 @@ static inline int port_type_to_port(int port_sel)
 #define _SBI_ADDR_OFFSET_SHIFT		16
 #define _SBI_ADDR_OFFSET_MASK		(0xffff << _SBI_ADDR_OFFSET_SHIFT)
 
+#define _REGBIT_REG_TRANS_SHIFT     12
+#define _REGBIT_REG_TRANS_MASK      (3<<_REGBIT_REG_TRANS_SHIFT)
 #define _REG_TRANS_DDI_FUNC_CTL_A	0x60400
 #define _REG_TRANS_DDI_FUNC_CTL_B	0x61400
 #define _REG_TRANS_DDI_FUNC_CTL_C	0x62400
diff --git a/drivers/gpu/drm/i915/vgt/sysfs.c b/drivers/gpu/drm/i915/vgt/sysfs.c
index 98ccf97..a4cbdd7 100644
--- a/drivers/gpu/drm/i915/vgt/sysfs.c
+++ b/drivers/gpu/drm/i915/vgt/sysfs.c
@@ -32,7 +32,7 @@ static void vgt_kobj_release(struct kobject *kobj)
 	//kfree(kobj);
 }
 
-static int vgt_add_state_sysfs(vgt_params_t vp);
+//static int vgt_add_state_sysfs(vgt_params_t vp);
 static int vgt_del_state_sysfs(vgt_params_t vp);
 static ssize_t vgt_create_instance_store(struct kobject *kobj, struct kobj_attribute *attr,
 			const char *buf, size_t count)
@@ -115,6 +115,7 @@ static ssize_t vgt_foreground_vm_store(struct kobject *kobj, struct kobj_attribu
 	struct vgt_device *next_vgt;
 	struct pgt_device *pdev = &default_device;
 	int cpu;
+	int pipe;
 
 	if (sscanf(buf, "%d", &vmid) != 1)
 		return -EINVAL;
@@ -130,9 +131,9 @@ static ssize_t vgt_foreground_vm_store(struct kobject *kobj, struct kobj_attribu
 		goto out;
 	}
 
-	if (current_foreground_vm(pdev) == next_vgt) {
-		goto out;
-	}
+//	if (current_foreground_vm(pdev) == next_vgt) {
+//		goto out;
+//	}
 
 	if (!__vreg(next_vgt, vgt_info_off(display_ready))) {
 		printk("VGT %d: Display is not ready.\n", vmid);
@@ -140,7 +141,10 @@ static ssize_t vgt_foreground_vm_store(struct kobject *kobj, struct kobj_attribu
 		goto out;
 	}
 
-	pdev->next_foreground_vm = next_vgt;
+	//pdev->next_foreground_vm = next_vgt;
+	for (pipe = PIPE_A; pipe < I915_MAX_PIPES; pipe++){
+		pdev->next_vgt_on_pipe[pipe] = next_vgt;
+	}
 	vgt_raise_request(pdev, VGT_REQUEST_DPY_SWITCH);
 out:
 	vgt_unlock_dev_flags(pdev, cpu, flags);
@@ -572,6 +576,7 @@ out:
 
 static ssize_t vgt_pport_owner_switch_store(struct kobject *kobj, struct kobj_attribute *attr,
 			const char *buf, size_t count);
+
 // show triggers switch to allow switching from non root
 static ssize_t vgt_pport_owner_switch_show(struct kobject *kobj, struct kobj_attribute *attr,
 				   char *buf)
@@ -616,14 +621,15 @@ static ssize_t vgt_pport_owner_store(struct kobject *kobj, struct kobj_attribute
         	if ((VGT_MMIO_READ(pgt,_VGT_TRANS_DDI_FUNC_CTL(j)) & 
         			_REGBIT_TRANS_DDI_PORT_MASK) >> _TRANS_DDI_PORT_SHIFT == i)
         		break;
+    
+        if (j > TRANSCODER_C){
+	        vgt_warn("port %s is not active\n", kobj->name);
+	        goto out;
+	    }
+	
+	    ppipe = j;
     }
 
-    if (j > TRANSCODER_C){
-        vgt_warn("port %s is not active\n", kobj->name);
-        goto out;
-    }
-
-    ppipe = j;
     next_vgt = vmid_2_vgt_device(vmid);
 
     if (next_vgt == NULL || pgt->vgt_on_pipe[ppipe] == next_vgt){
@@ -631,6 +637,8 @@ static ssize_t vgt_pport_owner_store(struct kobject *kobj, struct kobj_attribute
     	goto out;
     }
 
+    vgt_info("new vgt %d on %s",next_vgt->vm_id,VGT_PIPE_NAME(ppipe));
+
     pgt->next_vgt_on_pipe[ppipe] = next_vgt;
     vgt_raise_request(pgt, VGT_REQUEST_DPY_SWITCH);
 out:    
@@ -673,14 +681,15 @@ static ssize_t vgt_pport_owner_switch_store(struct kobject *kobj, struct kobj_at
         	if ((VGT_MMIO_READ(pgt,_VGT_TRANS_DDI_FUNC_CTL(j)) & 
         			_REGBIT_TRANS_DDI_PORT_MASK) >> _TRANS_DDI_PORT_SHIFT == i)
         		break;
-    }
+        if (j > TRANSCODER_C){
+        	vgt_warn("pport %s is not active\n", kobj->name);
+        	return 0;
+    	}
 
-    if (j > TRANSCODER_C){
-        vgt_warn("pport %s is not active\n", kobj->name);
-        return 0;
+    	ppipe = j;
     }
 
-    ppipe = j;
+//    vgt_info("pipe on port %s is %s",kobj->name,VGT_PIPE_NAME(ppipe));
 
     for (i = 0; i< VGT_MAX_VMS; i++)
     	if (pgt->device[i] == pgt->vgt_on_pipe[ppipe]) 
@@ -705,7 +714,7 @@ static ssize_t vgt_pport_owner_switch_store(struct kobject *kobj, struct kobj_at
 		return 0;
 	sprintf(temp_buf, "%d", next_vgt->vm_id);
 
-	vgt_info("owner store call %d ", next_vgt->vm_id);
+	vgt_info("owner store call %d \n", next_vgt->vm_id);
 	vgt_pport_owner_store(kobj, attr, &temp_buf[0], TMP_BUF_LEN);
 	return count;
 }
@@ -1205,7 +1214,7 @@ static struct bin_attribute igd_mmio_attr = {
 };
 
 
-static int vgt_add_state_sysfs(vgt_params_t vp)
+int vgt_add_state_sysfs(vgt_params_t vp)
 {
 	int retval, i;
 	struct vgt_device *vgt;
@@ -1225,6 +1234,9 @@ static int vgt_add_state_sysfs(vgt_params_t vp)
 
 	retval = create_vgt_instance(&default_device, &vgt, vp);
 
+	if (vp.vm_id == 0)
+		vgt_dom0 = vgt;
+
 	if (retval < 0)
 		return retval;
 
@@ -1236,6 +1248,7 @@ static int vgt_add_state_sysfs(vgt_params_t vp)
 
 	/* add kobject, NULL parent indicates using kset as parent */
 	retval = kobject_add(&vgt->kobj, NULL, "vm%u", vgt->vm_id);
+
 	if (retval) {
 		printk(KERN_WARNING "%s: vgt kobject add error: %d\n",
 					__func__, retval);
diff --git a/drivers/gpu/drm/i915/vgt/vgt.c b/drivers/gpu/drm/i915/vgt/vgt.c
index 406e9b0..0fcd289 100644
--- a/drivers/gpu/drm/i915/vgt/vgt.c
+++ b/drivers/gpu/drm/i915/vgt/vgt.c
@@ -135,7 +135,8 @@ module_param_named(bypass_scan, bypass_scan_mask, int, 0600);
 bool bypass_dom0_addr_check = false;
 module_param_named(bypass_dom0_addr_check, bypass_dom0_addr_check, bool, 0600);
 
-bool enable_panel_fitting = true;
+//bool enable_panel_fitting = true;
+bool enable_panel_fitting = false;
 module_param_named(enable_panel_fitting, enable_panel_fitting, bool, 0600);
 
 bool enable_reset = true;
@@ -730,13 +731,16 @@ static int vgt_initialize(struct pci_dev *dev)
 	/* init all mmio_device */
 	vgt_init_mmio_device(pdev);
 
+	vgt_init_sysfs(pdev);
+
 	/* create domain 0 instance */
 	vp.vm_id = 0;
 	vp.aperture_sz = dom0_low_gm_sz;
 	vp.gm_sz = dom0_low_gm_sz + dom0_high_gm_sz;
 	vp.fence_sz = dom0_fence_sz;
 	vp.vgt_primary = 1; /* this isn't actually used for dom0 */
-	if (create_vgt_instance(pdev, &vgt_dom0, vp) < 0)
+	if (vgt_add_state_sysfs(vp) < 0)
+//	if (create_vgt_instance(pdev, &vgt_dom0, vp) < 0)
 		goto err;
 
 	reset_cached_interrupt_registers(pdev);
@@ -797,8 +801,6 @@ static int vgt_initialize(struct pci_dev *dev)
 
 	list_add(&pdev->list, &pgt_devices);
 
-	vgt_init_sysfs(pdev);
-
 	vgt_init_fb_notify();
 
 	printk("vgt_initialize succeeds.\n");
diff --git a/drivers/gpu/drm/i915/vgt/vgt.h b/drivers/gpu/drm/i915/vgt/vgt.h
index 75f01ae..2c080b8 100644
--- a/drivers/gpu/drm/i915/vgt/vgt.h
+++ b/drivers/gpu/drm/i915/vgt/vgt.h
@@ -2729,6 +2729,7 @@ void vgt_release_instance(struct vgt_device *vgt);
 int vgt_init_sysfs(struct pgt_device *pdev);
 void vgt_destroy_sysfs(void);
 extern void vgt_clear_port(struct vgt_device *vgt, int index);
+int vgt_add_state_sysfs(vgt_params_t vp);
 void vgt_update_monitor_status(struct vgt_device *vgt);
 void vgt_detect_display(struct vgt_device *vgt, int index);
 void vgt_dpy_init_modes(vgt_reg_t *mmio_array);
-- 
1.9.1


From e147591991745e25fdec2da21a4e219ba2203abc Mon Sep 17 00:00:00 2001
From: Konstantin Anisimov <rrevenantt@gmail.com>
Date: Fri, 19 Jun 2015 05:02:59 +0300
Subject: [PATCH 3/3] some tests for getting virtual monitor data from VM
 memory

---
 drivers/gpu/drm/i915/vgt/debugfs.c   | 177 +++++++++++++++++++++++++++++++++++
 drivers/gpu/drm/i915/vgt/display.c   |  27 +++---
 drivers/gpu/drm/i915/vgt/gtt.c       |   2 +-
 drivers/gpu/drm/i915/vgt/handlers.c  |  38 +++++++-
 drivers/gpu/drm/i915/vgt/hypercall.h |   4 +
 drivers/gpu/drm/i915/vgt/interrupt.c |  14 +--
 drivers/gpu/drm/i915/vgt/vgt.h       |  28 +++++-
 drivers/xen/xengt.c                  |  99 ++++++++++++++++++++
 include/xen/interface/memory.h       |  63 +++++++++++++
 include/xen/interface/xen.h          |  52 +++++++++-
 10 files changed, 477 insertions(+), 27 deletions(-)

diff --git a/drivers/gpu/drm/i915/vgt/debugfs.c b/drivers/gpu/drm/i915/vgt/debugfs.c
index 78cc0f3..b6aa3fd 100644
--- a/drivers/gpu/drm/i915/vgt/debugfs.c
+++ b/drivers/gpu/drm/i915/vgt/debugfs.c
@@ -23,6 +23,8 @@
 #include <linux/module.h>
 #include <linux/pci.h>
 #include <linux/debugfs.h>
+#include <linux/mm.h>
+#include <xen/interface/xen.h>
 #include "fb_decoder.h"
 
 #include "vgt.h"
@@ -102,6 +104,7 @@ enum vgt_debugfs_entry_t
 	VGT_DEBUGFS_FB_FORMAT,
 	VGT_DEBUGFS_DPY_INFO,
 	VGT_DEBUGFS_VIRTUAL_GTT,
+	VGT_DEBUGFS_PIPEA_PRIMARY_SURF,
 	VGT_DEBUGFS_ENTRY_MAX
 };
 
@@ -472,6 +475,173 @@ static const struct file_operations fbinfo_fops = {
 	.release = single_release,
 };
 
+extern int vgt_decode_primary_plane_format(struct vgt_device *vgt,
+										   int pipe, struct vgt_primary_plane_format *plane);
+
+#define getbit(x,y) (((x) & (1 << (y))) >> (y))
+
+static int __attribute__((unused)) vgt_show_prisurfa(struct seq_file *m, void *data)
+{
+	struct vgt_device *vgt =  (struct vgt_device *)m->private;
+	//uint64_t gma = __vreg(vgt, VGT_DSPSURF(PIPE_A));
+	//uint64_t va = (uint64_t)vgt_gma_to_va(vgt->gtt.ggtt_mm, gma);
+	u_int i,j;
+	uint64_t time1 = ktime_to_ns(ktime_get());
+	uint64_t time2;
+	vgt_info(" time %lld\n",time1);
+//	struct vgt_primary_plane_format primary_plane_format;
+
+//	vgt_decode_primary_plane_format(vgt, PIPE_A, &primary_plane_format);
+
+	for (j = 0; j < 32; j++) {
+	//	uint64_t va = (uint64_t)vgt_gma_to_va(vgt->gtt.ggtt_mm, gma);
+		int k,l;
+
+		for (k = 0; k < 8; k++) {
+			uint64_t gma = VGT_MMIO_READ(vgt->pdev, _REG_DSPASURFLIVE) + j * 8 * (__vreg(vgt, VGT_DSPSTRIDE(PIPE_A)));
+
+			for (l = 0; l < 13; l++) {
+				uint64_t gma2 = gma + PAGE_SIZE*l;
+				uint64_t va2 = (uint64_t) vgt_gma_to_va(vgt->gtt.ggtt_mm, gma2);
+
+				for (i = 0; i < 512; i++) {
+					uint64_t vv = va2 + i + k * 512;
+					uint64_t vv2 = (vv & ~(((uint64_t) 1) << 6))
+								   | (((getbit(vv, 6)) ^ getbit(vv, 9) ^ getbit(vv, 10)) << 6);
+
+					seq_putc(m, *(char *) (vv2));
+				}
+
+			//	for (i = 0; i < 512; i++) {
+			//		uint64_t vv = va2 + i + l * 512;
+			//		uint64_t vv2 =
+			//				(vv & ~(((uint64_t) 1) << 6)) | (((getbit(vv, 6)) ^ getbit(vv, 9) ^ getbit(vv, 10)) << 6);
+
+			//		seq_putc(m, *(char *) (vv2));
+			//	}
+			}
+		}
+	}
+	time2 = ktime_to_ns(ktime_get());
+	printk("getdisplay time taken %lld\n", time2 - time1);
+	return 0;
+}
+
+static int  prisurfa_open(struct inode *inode, struct file *file)
+{
+	struct mmap_info* info = kmalloc(sizeof(struct mmap_info), GFP_KERNEL);
+	struct vgt_device* vgt = (struct vgt_device*)inode->i_private;
+	info->vgt = vgt;
+	info->data = (void*) get_zeroed_page(GFP_KERNEL);
+	*((uint64_t*) info->data) = 0x0101;
+	file->private_data = info;
+	vgt_info(" open");
+
+	return 0;//single_open(file, vgt_show_prisurfa, inode->i_private);
+}
+
+static int prisurfa_release(struct inode *inode, struct file *file)
+{
+	vgt_info(" release");
+	free_page((uint64_t)((struct mmap_info*)file->private_data)->data);
+	kfree(file->private_data);
+	return 0;//single_release(inode, file);
+}
+
+static void mmap_open(struct vm_area_struct *vma)
+{
+	struct mmap_info *info = (struct mmap_info *)vma->vm_private_data;
+	uint64_t handle;
+	struct vgt_device * vgt = (struct vgt_device *) vma->vm_private_data;
+	uint64_t gma = VGT_MMIO_READ(vgt->pdev, _REG_DSPASURFLIVE);
+	uint64_t gpa = (uint64_t)vgt_gma_to_gpa(vgt->gtt.ggtt_mm, gma);
+
+	int rc = hypervisor_xen_domctl_memsharing_nominate_share_gfn(vgt->vm_id, (char*)gpa, &handle);
+	if (rc != 0){
+		printk("memsharing _nominate error %d\n",rc);
+		//	goto err;
+	}
+	printk("memsharing _nominate OK  vm=%d\n", vgt->vm_id);
+
+	info->reference++;
+}
+
+static void mmap_close(struct vm_area_struct *vma)
+{
+	struct mmap_info *info = (struct mmap_info *)vma->vm_private_data;
+	info->reference--;
+}
+
+static int mmap_fault(struct vm_area_struct *vma,struct vm_fault * vmf)
+{
+//	struct vgt_device * vgt = (struct vgt_device *) vma->vm_private_data;
+//	uint64_t gma = VGT_MMIO_READ(vgt->pdev, _REG_DSPASURFLIVE);
+//	uint64_t gpa = (uint64_t)vgt_gma_to_gpa(vgt->gtt.ggtt_mm, gma);
+//	uint64_t mfn = hypervisor_g2m_pfn(vgt, gpa >> PAGE_SHIFT);
+//	uint64_t va = (uint64_t)vgt->mem_buf;//(uint64_t)vgt_gma_to_va(vgt->gtt.ggtt_mm, gma);
+	uint64_t va2 = (uint64_t)((struct mmap_info*)vma->vm_private_data)->data;//(uint64_t)kmalloc(PAGE_SIZE, GFP_USER);
+	struct page * page;
+/*
+	uint64_t handle;
+	int rc = hypervisor_xen_domctl_memsharing_nominate_share_gfn(vgt->vm_id, (char*)gpa, &handle);
+	if (rc != 0){
+		printk("memsharing _nominate error %d\n",rc);
+		//	goto err;
+	}
+	printk("memsharing _nominate OK  vm=%d\n", vgt->vm_id);
+
+	rc = hypervisor_xen_domctl_memsharing_share_gfn(vgt->vm_id, gpa >> PAGE_SHIFT, handle,
+													(va) >> PAGE_SHIFT, vgt->mem_handle);
+	if (rc != 0){
+		printk("memsharing share error %d\n",rc);
+		//	goto err;
+	}
+	printk("memsharing share OK  vm=%d\n", vgt->vm_id);
+	printk("%016llx",*(uint64_t*)va);
+*/
+//	int rc = hypervisor_map_mfn_to_gpfn(vmid_2_vgt_device(0), va >> PAGE_SHIFT, mfn, 1, DPCI_ADD_MAPPING);
+//	if (rc < 0){
+//		vgt_info("memsharing fail during fault rc=%d", rc);
+//	}
+
+	page = virt_to_page(va2);
+//	int i;
+//	struct vgt_primary_plane_format primary_plane_format;
+
+//	*(uint64_t*)va2 = 0x01010101;
+//	vgt_decode_primary_plane_format(vgt, PIPE_A, &primary_plane_format);
+
+	get_page(page);
+	vmf->page = page;
+
+	return 0;
+}
+
+static const struct vm_operations_struct mmap_vm_ops = {
+		.open = mmap_open,
+		.close = mmap_close,
+		.fault = mmap_fault,
+};
+
+static int prisurfa_mmap(struct file * file, struct vm_area_struct * vm_area)
+{
+	vm_area->vm_ops = &mmap_vm_ops;
+	vm_area->vm_flags |= VM_IO ;//| VM_SHARED | VM_IO ;
+	vm_area->vm_private_data = file->private_data;
+	vgt_info("mmap");
+	mmap_open(vm_area);
+	return 0;
+}
+
+static const struct file_operations prisurfa_fops = {
+		.open = prisurfa_open,
+//		.read = seq_read,
+//		.llseek = seq_lseek,
+		.release = prisurfa_release,
+		.mmap = prisurfa_mmap,
+};
+
+
 static inline vgt_reg_t vgt_get_mmio_value(struct pgt_device *pdev,
 		struct vgt_device *vgt, unsigned int reg)
 {
@@ -1114,6 +1284,13 @@ int vgt_create_debugfs(struct vgt_device *vgt)
 	else
 		printk("vGT(%d): create debugfs node: frame_buffer_format\n", vgt_id);
 
+	d_debugfs_entry[vgt_id][VGT_DEBUGFS_PIPEA_PRIMARY_SURF] = debugfs_create_file("pipea_primary_surf",
+			0444, d_per_vgt[vgt_id], vgt, &prisurfa_fops);
+	if (!d_debugfs_entry[vgt_id][VGT_DEBUGFS_FB_FORMAT])
+		printk(KERN_ERR "vGT(%d): failed to create debugfs node: pipea_primary_surf\n", vgt_id);
+	else
+		printk("vGT(%d): create debugfs node: pipea_primary_surf\n", vgt_id);
+
 	d_debugfs_entry[vgt_id][VGT_DEBUGFS_DPY_INFO] = debugfs_create_file("dpyinfo",
 			0444, d_per_vgt[vgt_id], vgt, &virt_dpyinfo_fops);
 
diff --git a/drivers/gpu/drm/i915/vgt/display.c b/drivers/gpu/drm/i915/vgt/display.c
index 08ca7a7..1afa262 100644
--- a/drivers/gpu/drm/i915/vgt/display.c
+++ b/drivers/gpu/drm/i915/vgt/display.c
@@ -129,6 +129,19 @@ void do_vgt_fast_display_switch(struct pgt_device *pdev)
 	ASSERT(fastpath_dpy_switch);
 	ASSERT(spin_is_locked(&pdev->lock));
 
+	to_vgt = pdev->next_foreground_vm;
+	if (to_vgt != current_foreground_vm(pdev)){
+		for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) 
+//			if (_PRI_PLANE_ENABLE & __vreg(to_vgt, VGT_DSPCNTR(pipe))) {
+//				pdev->vgt_on_pipe[to_vgt->pipe_mapping[pipe]] = to_vgt;
+//				vgt_restore_state(to_vgt, pipe);
+//				set_panel_fitting(to_vgt, pipe);
+//				
+//			}
+			pdev->next_vgt_on_pipe[pipe] = to_vgt;
+		current_foreground_vm(pdev) = to_vgt;
+	}
+
 	for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) 
 		if (pdev->next_vgt_on_pipe[pipe] != NULL ){
 			enum vgt_pipe vpipe;
@@ -149,19 +162,7 @@ void do_vgt_fast_display_switch(struct pgt_device *pdev)
 			vgt_restore_state(to_vgt, vpipe);
 			set_panel_fitting(to_vgt, vpipe);
 			pdev->next_vgt_on_pipe[pipe] = NULL;				
-		}
-
-	to_vgt = pdev->next_foreground_vm;
-	if (to_vgt != current_foreground_vm(pdev)){
-		for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) 
-			if (_PRI_PLANE_ENABLE & __vreg(to_vgt, VGT_DSPCNTR(pipe))) {
-				pdev->vgt_on_pipe[to_vgt->pipe_mapping[pipe]] = to_vgt;
-				vgt_restore_state(to_vgt, pipe);
-				set_panel_fitting(to_vgt, pipe);
-				
-			}
-		current_foreground_vm(pdev) = to_vgt;
-	} 
+		} 
 	
 }
 
diff --git a/drivers/gpu/drm/i915/vgt/gtt.c b/drivers/gpu/drm/i915/vgt/gtt.c
index 9d6d6d0..97a32c0 100644
--- a/drivers/gpu/drm/i915/vgt/gtt.c
+++ b/drivers/gpu/drm/i915/vgt/gtt.c
@@ -1246,7 +1246,7 @@ static inline bool ppgtt_get_next_level_entry(struct vgt_mm *mm,
 	return true;
 }
 
-static inline unsigned long vgt_gma_to_gpa(struct vgt_mm *mm, unsigned long gma)
+unsigned long vgt_gma_to_gpa(struct vgt_mm *mm, unsigned long gma)
 {
 	struct vgt_device *vgt = mm->vgt;
 	struct pgt_device *pdev = vgt->pdev;
diff --git a/drivers/gpu/drm/i915/vgt/handlers.c b/drivers/gpu/drm/i915/vgt/handlers.c
index 5fca786..a173926 100644
--- a/drivers/gpu/drm/i915/vgt/handlers.c
+++ b/drivers/gpu/drm/i915/vgt/handlers.c
@@ -1303,6 +1303,7 @@ static bool dpy_plane_mmio_write(struct vgt_device *vgt, unsigned int offset,
 {
 	unsigned int real_offset;
 
+
 	memcpy ((char *)vgt->state.vReg + offset, p_data, bytes);
 	memcpy ((char *)vgt->state.sReg + offset, p_data, bytes);
 	if (vgt_map_plane_reg(vgt, offset, &real_offset) &&
@@ -1391,12 +1392,12 @@ static bool dpy_plane_ctl_write(struct vgt_device *vgt, unsigned int offset,
 
 	dpy_plane_mmio_write(vgt, offset, p_data, bytes);
 	if (enable_plane) {
-//		if (current_foreground_vm(vgt->pdev) == vgt) {
-		if (vgt->pdev->vgt_on_pipe[vgt->pipe_mapping[pipe]] == vgt){
+		if (current_foreground_vm(vgt->pdev) == vgt) {
+//		if (vgt->pdev->vgt_on_pipe[vgt->pipe_mapping[pipe]] == vgt){
 			set_panel_fitting(vgt, pipe);
 		} else if (is_current_display_owner(vgt)) {
 			p_pipe = vgt->pipe_mapping[pipe];
-			foreground_vgt = vgt->pdev->vgt_on_pipe[p_pipe];//current_foreground_vm(vgt->pdev);
+			foreground_vgt = current_foreground_vm(vgt->pdev);
 			for (i = 0; i < I915_MAX_PIPES; i++) {
 				if (foreground_vgt->pipe_mapping[i] == p_pipe) {
 					v_pipe = i;
@@ -1421,11 +1422,42 @@ static bool pri_surf_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	enum vgt_pipe pipe = VGT_DSPSURFPIPE(offset);
 	unsigned int real_offset;
 	vgt_reg_t ret_val;
+	uint64_t gma = *(uint32_t*)p_data;
+//	uint64_t data2, data3;
+//	hypervisor_read_va(vgt, (void *)va, &data2, 4, true);
+//	hypervisor_read_va(vgt, (void *)va2, &data3, 4, true);
 
 	__vreg(vgt, offset) = *(vgt_reg_t*)p_data;
 	ret_val = vgt_surf_base_range_check(vgt, pipe, PRIMARY_PLANE);
 	__sreg(vgt, offset) = ret_val ? ret_val : __vreg(vgt, offset);
 
+	if(vgt->hvm_boot_foreground_visible && gma != 0) {
+		//char* data = vz;
+//		int i;
+//		uint64_t gpa = (uint64_t)vgt_gma_to_gpa(vgt->gtt.ggtt_mm, gma); //hypervisor_g2m_pfn(vgt, gva >> PAGE_SHIFT) << PAGE_SHIFT;
+//		uint64_t pa = (uint64_t)hypervisor_g2m_pfn(vgt, gpa >> PAGE_SHIFT) << PAGE_SHIFT;
+//		uint64_t va = (uint64_t)hypervisor_mfn_to_virt(pa >> PAGE_SHIFT);
+		uint64_t va2 = (uint64_t)vgt_gma_to_va(vgt->gtt.ggtt_mm, gma);
+//		uint64_t va3 = (uint64_t)hypervisor_gpa_to_va(vgt, gpa);
+
+
+
+		printk("memsharing%d, va = %llx,\n", vgt->vm_id, va2);
+
+		//hypervisor_read_va(vgt, (void *)va2, vgt->mem_buf, 4, true);
+		//printk("memsharing%d,  data = %llx\n", vgt->vm_id, data);
+
+
+		//hypervisor_read_va(vgt, (void *)va2+8, &data, 4, true);
+//		memcpy(vgt->mem_buf, (void *)va2 ,64);
+//		printk("memsharing%d,  data = ", vgt->vm_id);
+//		for(i = 0; i < 64; i++) {
+//			uint8_t * a = (uint8_t *)vgt->mem_buf;
+//			printk("%02x", *(a+i));
+//		}
+//		printk("\n");
+	}
+
 	__vreg(vgt, VGT_PIPE_FLIPCOUNT(pipe))++;
 
 	if (vgt_map_plane_reg(vgt, offset, &real_offset) &&
diff --git a/drivers/gpu/drm/i915/vgt/hypercall.h b/drivers/gpu/drm/i915/vgt/hypercall.h
index 6f83bc4..60a6d34 100644
--- a/drivers/gpu/drm/i915/vgt/hypercall.h
+++ b/drivers/gpu/drm/i915/vgt/hypercall.h
@@ -40,6 +40,10 @@ struct kernel_dm {
 	void *(*gpa_to_va)(struct vgt_device *vgt, unsigned long gap);
 	bool (*read_va)(struct vgt_device *vgt, void *va, void *val, int len, int atomic);
 	bool (*write_va)(struct vgt_device *vgt, void *va, void *val, int len, int atomic);
+	int (*memsharing_enable) (int vm_id);
+	int (*domctl_memsharing_nominate_share_gfn)(int vm_id, char * guest_addr, uint64_t * handle);
+	int (*domctl_memsharing_share_gfn) (int vm_id, uint64_t source_gfn, uint64_t source_handle,
+											uint64_t client_gfn, uint64_t client_handle);
 };
 
 #endif /* _VGT_HYPERCALL_H_ */
diff --git a/drivers/gpu/drm/i915/vgt/interrupt.c b/drivers/gpu/drm/i915/vgt/interrupt.c
index 309032f..a58ae62 100644
--- a/drivers/gpu/drm/i915/vgt/interrupt.c
+++ b/drivers/gpu/drm/i915/vgt/interrupt.c
@@ -1320,13 +1320,6 @@ static void vgt_handle_port_hotplug_phys(struct vgt_irq_host_state *hstate,
 		vgt_warn("IRQ: captured port hotplug event when HPD is disabled\n");
 	}
 
-	tmp = hotplug_ctrl & ~(_REGBIT_DP_B_STATUS |
-				_REGBIT_DP_C_STATUS |
-				_REGBIT_DP_D_STATUS);
-	tmp |= hotplug_ctrl & status_mask;
-	/* write back value to clear specific port status */
-	VGT_MMIO_WRITE(pdev, _REG_SHOTPLUG_CTL, tmp);
-
 	if (hotplug_ctrl & status_mask) {
 		vgt_info("IRQ: detect monitor insert event on port!\n");
 		vgt_set_uevent(vgt_dom0, hotplug_event);
@@ -1335,6 +1328,13 @@ static void vgt_handle_port_hotplug_phys(struct vgt_irq_host_state *hstate,
 		vgt_set_uevent(vgt_dom0, hotplug_event + 1);
 	}
 
+	tmp = hotplug_ctrl & ~(_REGBIT_DP_B_STATUS |
+				_REGBIT_DP_C_STATUS |
+				_REGBIT_DP_D_STATUS);
+	tmp |= hotplug_ctrl & status_mask;
+	/* write back value to clear specific port status */
+	VGT_MMIO_WRITE(pdev, _REG_SHOTPLUG_CTL, tmp);
+
 	if (propagate_monitor_to_guest)
 		vgt_set_uevent(vgt_dom0, detect_event);
 
diff --git a/drivers/gpu/drm/i915/vgt/vgt.h b/drivers/gpu/drm/i915/vgt/vgt.h
index 2c080b8..03a654f 100644
--- a/drivers/gpu/drm/i915/vgt/vgt.h
+++ b/drivers/gpu/drm/i915/vgt/vgt.h
@@ -762,6 +762,12 @@ struct vgt_statistics {
 	u64	skip_bb_cnt;
 };
 
+struct mmap_info {
+	struct vgt_device *vgt;	/* the data */
+	void * data;
+	int reference;       /* how many times it is mmapped */
+};
+
 /* per-VM structure */
 typedef cycles_t vgt_tslice_t;
 struct vgt_sched_info {
@@ -884,6 +890,8 @@ struct vgt_device {
 
 	struct gt_port		ports[I915_MAX_PORTS]; /* one port per PIPE */
 	struct vgt_i2c_edid_t	vgt_i2c_edid;	/* i2c bus state emulaton for reading EDID */
+	void*		mem_buf;
+	uint64_t	mem_handle;
 
 	uint64_t	aperture_base;
 	void		*aperture_base_va;
@@ -2761,7 +2769,7 @@ extern bool gtt_emulate_write(struct vgt_device *vgt, unsigned int off,
 #define INVALID_ADDR (~0UL)
 
 extern void* vgt_gma_to_va(struct vgt_mm *mm, unsigned long gma);
-
+extern unsigned long vgt_gma_to_gpa(struct vgt_mm *mm, unsigned long gma);
 
 #define INVALID_MFN	(~0UL)
 
@@ -2921,6 +2929,24 @@ static inline void reset_el_structure(struct pgt_device *pdev,
 
 extern struct kernel_dm *vgt_pkdm;
 
+//static inline int hypervisor_memsharing_enable(struct vgt_device *vgt)
+//{
+//	return vgt_pkdm->memsharing_enable(vgt->vm_id);
+//}
+
+static inline __attribute__((unused)) int hypervisor_xen_domctl_memsharing_share_gfn
+		(int vm_id, uint64_t source_gfn, uint64_t source_handle,
+		 uint64_t client_gfn, uint64_t client_handle)
+{
+	return vgt_pkdm->domctl_memsharing_share_gfn(vm_id, source_gfn, source_handle,client_gfn, client_handle);
+}
+
+static inline int hypervisor_xen_domctl_memsharing_nominate_share_gfn
+		(int vm_id, char * guest_addr, uint64_t * handle)
+{
+	return vgt_pkdm->domctl_memsharing_nominate_share_gfn(vm_id, guest_addr, handle);
+}
+
 static inline unsigned long hypervisor_g2m_pfn(struct vgt_device *vgt,
 	unsigned long g_pfn)
 {
diff --git a/drivers/xen/xengt.c b/drivers/xen/xengt.c
index 37360ff..db92660 100644
--- a/drivers/xen/xengt.c
+++ b/drivers/xen/xengt.c
@@ -46,8 +46,13 @@
 #include <xen/interface/memory.h>
 #include <xen/interface/platform.h>
 #include <xen/interface/vcpu.h>
+//#include <linux/slab.h>
+//#include <linux/err.h>
+//#include <asm-generic/page.h>
+//#include <xen/xen.h>
 
 #include "vgt.h"
+//#include "../gpu/drm/i915/vgt/vgt.h"
 
 MODULE_AUTHOR("Intel Corporation");
 MODULE_DESCRIPTION("XenGT mediated passthrough driver");
@@ -83,6 +88,66 @@ struct vgt_hvm_info {
 	struct vm_struct **vmem_vma_4k;
 };
 
+/* enable memory sharing in xen so we can share pages instead of copying them */
+int xen_domctl_memsharing_enable(int vm_id){
+	int rc;
+	struct xen_domctl domctl;
+
+	domctl.domain = vm_id;
+	domctl.cmd = XEN_DOMCTL_mem_sharing_op;
+    domctl.interface_version = XEN_DOMCTL_INTERFACE_VERSION;
+    domctl.u.mem_sharing_op.op = XEN_DOMCTL_MEM_SHARING_CONTROL;
+    domctl.u.mem_sharing_op.u.enable = true;
+
+    rc = HYPERVISOR_domctl(&domctl);
+	if (rc != 0)
+		printk("HYPERVISOR_domctl XEN_DOMCTL_MEM_SHARING_CONTROL fail with %d!\n", rc);
+
+	return rc;
+}
+
+static int xen_domctl_memsharing_nominate_share_gfn(int vm_id, char * guest_addr, uint64_t * handle)
+{
+	int rc;
+	struct xen_mem_sharing_op mso;
+	memset(&mso, 0, sizeof(mso));
+
+	mso.op = XENMEM_sharing_op_nominate_gfn;
+	mso.domain = vm_id;
+	mso.u.nominate.u.gfn = (u_int64_t)guest_addr >> PAGE_SHIFT;
+
+	rc = HYPERVISOR_memory_op(XENMEM_sharing_op_nominate_gfn, &mso);
+	if(rc < 0)
+		printk(" failed to nominate gfn for share err=%d\n", rc);
+
+
+	(*handle) = mso.u.nominate.handle;
+	return rc;
+}
+
+static int xen_domctl_memsharing_share_gfn(int vm_id, uint64_t source_gfn, uint64_t source_handle,
+		uint64_t client_gfn, uint64_t client_handle)
+{
+	int rc;
+	struct xen_mem_sharing_op mso;
+	memset(&mso, 0, sizeof(mso));
+
+	mso.op = XENMEM_sharing_op_share;
+	mso.domain = vm_id;
+	mso.u.share.client_gfn = client_gfn;
+	mso.u.share.client_handle = client_handle;
+	mso.u.share.source_gfn = source_gfn;
+	mso.u.share.source_handle = source_handle;
+	mso.u.share.client_domain = 0;
+
+	rc = HYPERVISOR_memory_op(XENMEM_sharing_op_share, &mso);
+	if(rc < 0)
+		printk(" failed to share gfns  err=%d\n", rc);
+
+	return rc;
+}
+
+
 /* Translate from VM's guest pfn to machine pfn */
 static unsigned long xen_g2m_pfn(int vm_id, unsigned long g_pfn)
 {
@@ -952,6 +1017,7 @@ static int xen_hvm_init(struct vgt_device *vgt)
 	int vcpu, irq, rc = 0;
 	struct task_struct *thread;
 	struct pgt_device *pdev = vgt->pdev;
+	char * test_buffer1;
 
 	info = kzalloc(sizeof(struct vgt_hvm_info), GFP_KERNEL);
 	if (info == NULL)
@@ -1001,6 +1067,35 @@ static int xen_hvm_init(struct vgt_device *vgt)
 		info->evtchn_irq[vcpu] = irq;
 	}
 
+	rc = xen_domctl_memsharing_enable(vgt->vm_id);
+	if (rc != 0){
+		printk("memsharing _enable error %d\n",rc);
+	//	goto err;
+	}
+
+	printk("memsharing _enable OK  vm = %d \n", vgt->vm_id);
+
+	vgt->mem_buf = (void *)get_zeroed_page(GFP_KERNEL);
+
+	rc = xen_domctl_memsharing_nominate_share_gfn(0, test_buffer1, &vgt->mem_handle);
+	if (rc != 0){
+		printk("memsharing _nominate error %d\n",rc);
+		//	goto err;
+	}
+	printk("memsharing _nominate OK  vm=%d\n", vgt->vm_id);
+
+//	rc = xen_domctl_memsharing_share_gfn(0,
+//			(uint64_t)test_buffer2 >> PAGE_SHIFT, handle2,
+//			(uint64_t)test_buffer1 >> PAGE_SHIFT, handle1);
+//	if (rc != 0){
+//		printk("memsharing _share error %d\n",rc);
+//		//	goto err;
+//	}
+//	printk("memsharing _share OK  vm=%d\n", vgt->vm_id);
+//
+//	printk("memsharing result buf1 = %lld, buf2 = %lld\n",
+//		   *(uint64_t *)test_buffer1,*(uint64_t *)test_buffer2);
+
 	thread = kthread_run(vgt_emulation_thread, vgt,
 			"vgt_emulation:%d", vgt->vm_id);
 	if(IS_ERR(thread))
@@ -1072,6 +1167,7 @@ static bool xen_write_va(struct vgt_device *vgt, void *va, void *val,
 	return true;
 }
 
+
 static struct kernel_dm xen_kdm = {
 	.g2m_pfn = xen_g2m_pfn,
 	.pause_domain = xen_pause_domain,
@@ -1089,6 +1185,9 @@ static struct kernel_dm xen_kdm = {
 	.gpa_to_va = xen_gpa_to_va,
 	.read_va = xen_read_va,
 	.write_va = xen_write_va,
+//	.memsharing_enable = xen_domctl_memsharing_enable,
+	.domctl_memsharing_nominate_share_gfn = xen_domctl_memsharing_nominate_share_gfn,
+	.domctl_memsharing_share_gfn = xen_domctl_memsharing_share_gfn,
 };
 
 struct kernel_dm *vgt_pkdm = &xen_kdm;
diff --git a/include/xen/interface/memory.h b/include/xen/interface/memory.h
index 6b16a42..90a0026 100644
--- a/include/xen/interface/memory.h
+++ b/include/xen/interface/memory.h
@@ -274,6 +274,69 @@ DEFINE_GUEST_HANDLE_STRUCT(xen_get_mfn_from_pfn);
  */
 extern spinlock_t xen_reservation_lock;
 
+#ifndef uint64_aligned_t
+#define uint64_aligned_t uint64_t
+#endif
+
+#define XENMEM_sharing_op                   22
+#define XENMEM_sharing_op_nominate_gfn      0
+#define XENMEM_sharing_op_nominate_gref     1
+#define XENMEM_sharing_op_share             2
+#define XENMEM_sharing_op_resume            3
+#define XENMEM_sharing_op_debug_gfn         4
+#define XENMEM_sharing_op_debug_mfn         5
+#define XENMEM_sharing_op_debug_gref        6
+#define XENMEM_sharing_op_add_physmap       7
+#define XENMEM_sharing_op_audit             8
+
+#define XENMEM_SHARING_OP_S_HANDLE_INVALID  (-10)
+#define XENMEM_SHARING_OP_C_HANDLE_INVALID  (-9)
+
+/* The following allows sharing of grant refs. This is useful
+ * for sharing utilities sitting as "filters" in IO backends
+ * (e.g. memshr + blktap(2)). The IO backend is only exposed
+ * to grant references, and this allows sharing of the grefs */
+#define XENMEM_SHARING_OP_FIELD_IS_GREF_FLAG   (1ULL << 62)
+
+#define XENMEM_SHARING_OP_FIELD_MAKE_GREF(field, val)  \
+    (field) = (XENMEM_SHARING_OP_FIELD_IS_GREF_FLAG | val)
+#define XENMEM_SHARING_OP_FIELD_IS_GREF(field)         \
+    ((field) & XENMEM_SHARING_OP_FIELD_IS_GREF_FLAG)
+#define XENMEM_SHARING_OP_FIELD_GET_GREF(field)        \
+    ((field) & (~XENMEM_SHARING_OP_FIELD_IS_GREF_FLAG))
+
+struct xen_mem_sharing_op {
+    uint8_t     op;     /* XENMEM_sharing_op_* */
+    domid_t     domain;
+
+    union {
+        struct mem_sharing_op_nominate {  /* OP_NOMINATE_xxx           */
+            union {
+                uint64_aligned_t gfn;     /* IN: gfn to nominate       */
+                uint32_t      grant_ref;  /* IN: grant ref to nominate */
+            } u;
+            uint64_aligned_t  handle;     /* OUT: the handle           */
+        } nominate;
+        struct mem_sharing_op_share {     /* OP_SHARE/ADD_PHYSMAP */
+            uint64_aligned_t source_gfn;    /* IN: the gfn of the source page */
+            uint64_aligned_t source_handle; /* IN: handle to the source page */
+            uint64_aligned_t client_gfn;    /* IN: the client gfn */
+            uint64_aligned_t client_handle; /* IN: handle to the client page */
+            domid_t  client_domain; /* IN: the client domain id */
+        } share;
+        struct mem_sharing_op_debug {     /* OP_DEBUG_xxx */
+            union {
+                uint64_aligned_t gfn;      /* IN: gfn to debug          */
+                uint64_aligned_t mfn;      /* IN: mfn to debug          */
+                uint32_t gref;     /* IN: gref to debug         */
+            } u;
+        } debug;
+    } u;
+};
+typedef struct xen_mem_sharing_op xen_mem_sharing_op_t;
+DEFINE_GUEST_HANDLE_STRUCT(xen_mem_sharing_op_t);
+
+
 /*
  * Unmaps the page appearing at a particular GPFN from the specified guest's
  * pseudophysical address space.
diff --git a/include/xen/interface/xen.h b/include/xen/interface/xen.h
index aacc4e4..dd360f9 100644
--- a/include/xen/interface/xen.h
+++ b/include/xen/interface/xen.h
@@ -795,8 +795,55 @@ DEFINE_GUEST_HANDLE_STRUCT(xen_domctl_getdomaininfo);
 #define XEN_DOMCTL_INTERFACE_VERSION 0x0000000a
 #define XEN_DOMCTL_pausedomain                    3
 #define XEN_DOMCTL_getdomaininfo                  5
-#define XEN_DOMCTL_memory_mapping                 39
-#define XEN_DOMCTL_iomem_permission               20
+#define XEN_DOMCTL_memory_mapping                39
+#define XEN_DOMCTL_iomem_permission              20
+#define XEN_DOMCTL_mem_sharing_op                57
+
+/*
+ * Sharing ENOMEM helper.
+ *
+ * As with paging, use the domctl for teardown/setup of the
+ * helper<->hypervisor interface.
+ *
+ * If setup, this ring is used to communicate failed allocations
+ * in the unshare path. XENMEM_sharing_op_resume is used to wake up
+ * vcpus that could not unshare.
+ *
+ * Note that shring can be turned on (as per the domctl below)
+ * *without* this ring being setup.
+ */
+#define XEN_DOMCTL_MEM_EVENT_OP_SHARING           3
+
+#define XEN_DOMCTL_MEM_EVENT_OP_SHARING_ENABLE    0
+#define XEN_DOMCTL_MEM_EVENT_OP_SHARING_DISABLE   1
+
+/* Use for teardown/setup of helper<->hypervisor interface for paging, 
+ * access and sharing.*/
+struct xen_domctl_mem_event_op {
+    uint32_t       op;           /* XEN_DOMCTL_MEM_EVENT_OP_*_* */
+    uint32_t       mode;         /* XEN_DOMCTL_MEM_EVENT_OP_* */
+
+    uint32_t port;              /* OUT: event channel for ring */
+};
+typedef struct xen_domctl_mem_event_op xen_domctl_mem_event_op_t;
+DEFINE_GUEST_HANDLE_STRUCT(xen_domctl_mem_event_op_t);
+
+/*
+ * Memory sharing operations
+ */
+/* XEN_DOMCTL_mem_sharing_op.
+ * The CONTROL sub-domctl is used for bringup/teardown. */
+#define XEN_DOMCTL_MEM_SHARING_CONTROL          0
+
+struct xen_domctl_mem_sharing_op {
+    uint8_t op; /* XEN_DOMCTL_MEM_SHARING_* */
+
+    union {
+        uint8_t enable;                   /* CONTROL */
+    } u;
+};
+typedef struct xen_domctl_mem_sharing_op xen_domctl_mem_sharing_op_t;
+DEFINE_GUEST_HANDLE_STRUCT(xen_domctl_mem_sharing_op_t);
 
 
 #define XEN_DOMCTL_vgt_io_trap			  700
@@ -848,6 +895,7 @@ struct xen_domctl {
 		struct xen_domctl_vgt_io_trap       vgt_io_trap;
 		struct xen_domctl_memory_mapping    memory_mapping;
 		struct xen_domctl_iomem_permission 	iomem_perm;
+		struct xen_domctl_mem_sharing_op    mem_sharing_op;
 		uint8_t                             pad[256];
 	}u;
 };
-- 
1.9.1

